{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpzHDTSwBy9XW/GGozOXPa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook is modified from a [LSTM Tutorial](https://github.com/nicodjimenez/lstm), which implements a minimal LSTM, both forward and backward, by NumPy."],"metadata":{"id":"i-zDmMNe_qUC"}},{"cell_type":"code","execution_count":41,"metadata":{"id":"VCb2LbO-Y5bK","executionInfo":{"status":"ok","timestamp":1684711819975,"user_tz":-120,"elapsed":211,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","source":["# import os\n","# %cd /content/drive/MyDrive/graduation_project/FPTT-on-ANN/RNN/lstm-master/\n","# !pwd"],"metadata":{"id":"JPxDL637ZC-5","executionInfo":{"status":"ok","timestamp":1684711820632,"user_tz":-120,"elapsed":436,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","import numpy as np\n","import math"],"metadata":{"id":"K8TVBLKFfMu-","executionInfo":{"status":"ok","timestamp":1684711820633,"user_tz":-120,"elapsed":22,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def sigmoid(x): \n","    return 1. / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(values): \n","    return values*(1-values)\n","\n","def tanh_derivative(values): \n","    return 1. - values ** 2"],"metadata":{"id":"ZcFDa7O0fVOt","executionInfo":{"status":"ok","timestamp":1684711820634,"user_tz":-120,"elapsed":22,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# createst uniform random array w/ values in [a,b) and shape args\n","def rand_arr(a, b, *args): \n","    np.random.seed(0)\n","    return np.random.rand(*args) * (b - a) + a"],"metadata":{"id":"ze4NU1jSfXqF","executionInfo":{"status":"ok","timestamp":1684711820634,"user_tz":-120,"elapsed":21,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["class LstmParam:\n","    def __init__(self, mem_cell_ct, x_dim):\n","        self.mem_cell_ct = mem_cell_ct\n","        self.x_dim = x_dim\n","        concat_len = x_dim + mem_cell_ct\n","        # weight matrices\n","        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n","        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n","        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n","        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n","        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n","        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n","        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n","        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct) \n","\n","        self.rm_wg = self.wg\n","        self.rm_wi = self.wi\n","        self.rm_wf = self.wf\n","        self.rm_wo = self.wo\n","        self.rm_bg = self.bg\n","        self.rm_bi = self.bi\n","        self.rm_bf = self.bf\n","        self.rm_bo = self.bo\n","\n","        self.lbd_wg = np.zeros((mem_cell_ct, concat_len)) \n","        self.lbd_wi = np.zeros((mem_cell_ct, concat_len)) \n","        self.lbd_wf = np.zeros((mem_cell_ct, concat_len)) \n","        self.lbd_wo = np.zeros((mem_cell_ct, concat_len)) \n","        self.lbd_bg = np.zeros(mem_cell_ct) \n","        self.lbd_bi = np.zeros(mem_cell_ct) \n","        self.lbd_bf = np.zeros(mem_cell_ct) \n","        self.lbd_bo = np.zeros(mem_cell_ct) \n","\n","        # diffs (derivative of loss function w.r.t. all parameters)\n","        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n","        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n","        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n","        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n","        self.bg_diff = np.zeros(mem_cell_ct) \n","        self.bi_diff = np.zeros(mem_cell_ct) \n","        self.bf_diff = np.zeros(mem_cell_ct) \n","        self.bo_diff = np.zeros(mem_cell_ct) \n","\n","    def apply_diff(self, lr = 1):\n","        self.wg -= lr * self.wg_diff\n","        self.wi -= lr * self.wi_diff\n","        self.wf -= lr * self.wf_diff\n","        self.wo -= lr * self.wo_diff\n","        self.bg -= lr * self.bg_diff\n","        self.bi -= lr * self.bi_diff\n","        self.bf -= lr * self.bf_diff\n","        self.bo -= lr * self.bo_diff\n","        # reset diffs to zero\n","        self.wg_diff = np.zeros_like(self.wg)\n","        self.wi_diff = np.zeros_like(self.wi) \n","        self.wf_diff = np.zeros_like(self.wf) \n","        self.wo_diff = np.zeros_like(self.wo) \n","        self.bg_diff = np.zeros_like(self.bg)\n","        self.bi_diff = np.zeros_like(self.bi) \n","        self.bf_diff = np.zeros_like(self.bf) \n","        self.bo_diff = np.zeros_like(self.bo) \n","\n","\n","\n","    def apply_diff_fptt(self, lr = 1, alpha = 0.001):\n","        self.wg -= lr * (self.wg_diff - self.lbd_wg + alpha*(self.wg - self.rm_wg))\n","        self.wi -= lr * (self.wi_diff - self.lbd_wi + alpha*(self.wi - self.rm_wi))\n","        self.wf -= lr * (self.wf_diff - self.lbd_wf + alpha*(self.wf - self.rm_wf))\n","        self.wo -= lr * (self.wo_diff - self.lbd_wo + alpha*(self.wo - self.rm_wo))\n","        self.bg -= lr * (self.bg_diff - self.lbd_bg + alpha*(self.bg - self.rm_bg))\n","        self.bi -= lr * (self.bi_diff - self.lbd_bi + alpha*(self.bi - self.rm_bi))\n","        self.bf -= lr * (self.bf_diff - self.lbd_bf + alpha*(self.bf - self.rm_bf))\n","        self.bo -= lr * (self.bo_diff - self.lbd_bo + alpha*(self.bo - self.rm_bo))\n","\n","        self.lbd_wg -= alpha*(self.wg - self.rm_wg)\n","        self.lbd_wi -= alpha*(self.wi - self.rm_wi)\n","        self.lbd_wf -= alpha*(self.wf - self.rm_wf)\n","        self.lbd_wo -= alpha*(self.wo - self.rm_wo)\n","        self.lbd_bg -= alpha*(self.bg - self.rm_bg)\n","        self.lbd_bi -= alpha*(self.bi - self.rm_bi)\n","        self.lbd_bf -= alpha*(self.bf - self.rm_bf)\n","        self.lbd_bo -= alpha*(self.bo - self.rm_bo)\n","\n","        self.rm_wg = 0.5*(self.rm_wg + self.wg) - (0.5/alpha)*self.lbd_wg \n","        self.rm_wi = 0.5*(self.rm_wi + self.wi) - (0.5/alpha)*self.lbd_wi\n","        self.rm_wf = 0.5*(self.rm_wf + self.wf) - (0.5/alpha)*self.lbd_wf\n","        self.rm_wo = 0.5*(self.rm_wo + self.wo) - (0.5/alpha)*self.lbd_wo\n","        self.rm_bg = 0.5*(self.rm_bg + self.bg) - (0.5/alpha)*self.lbd_bg\n","        self.rm_bi = 0.5*(self.rm_bi + self.bi) - (0.5/alpha)*self.lbd_bi\n","        self.rm_bf = 0.5*(self.rm_bf + self.bf) - (0.5/alpha)*self.lbd_bf\n","        self.rm_bo = 0.5*(self.rm_bo + self.bo) - (0.5/alpha)*self.lbd_bo\n","\n","\n","        # reset diffs to zero\n","        self.wg_diff = np.zeros_like(self.wg)\n","        self.wi_diff = np.zeros_like(self.wi) \n","        self.wf_diff = np.zeros_like(self.wf) \n","        self.wo_diff = np.zeros_like(self.wo) \n","        self.bg_diff = np.zeros_like(self.bg)\n","        self.bi_diff = np.zeros_like(self.bi) \n","        self.bf_diff = np.zeros_like(self.bf) \n","        self.bo_diff = np.zeros_like(self.bo)"],"metadata":{"id":"pRJm99HEfdCc","executionInfo":{"status":"ok","timestamp":1684711820635,"user_tz":-120,"elapsed":20,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["class LstmState:\n","    def __init__(self, mem_cell_ct, x_dim):\n","        self.g = np.zeros(mem_cell_ct)\n","        self.i = np.zeros(mem_cell_ct)\n","        self.f = np.zeros(mem_cell_ct)\n","        self.o = np.zeros(mem_cell_ct)\n","        self.s = np.zeros(mem_cell_ct)\n","        self.h = np.zeros(mem_cell_ct)\n","        self.bottom_diff_h = np.zeros_like(self.h)\n","        self.bottom_diff_s = np.zeros_like(self.s)\n","   "],"metadata":{"id":"MHOBOJZEhdAl","executionInfo":{"status":"ok","timestamp":1684711820636,"user_tz":-120,"elapsed":20,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["class LstmNode:\n","    def __init__(self, lstm_param, lstm_state):\n","        # store reference to parameters and to activations\n","        self.state = lstm_state\n","        self.param = lstm_param\n","        # non-recurrent input concatenated with recurrent input\n","        self.xc = None\n","\n","    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n","        # if this is the first lstm node in the network\n","        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n","        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n","        # save data for use in backprop\n","        self.s_prev = s_prev\n","        self.h_prev = h_prev\n","\n","        # concatenate x(t) and h(t-1)\n","        xc = np.hstack((x,  h_prev))\n","        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n","        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n","        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n","        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n","        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n","        self.state.h = self.state.s * self.state.o\n","\n","        self.xc = xc\n","\n","\n","    ''' original BPTT method\n","        calculate the gradient of onward Loss w.r.t. h/s at a specific time step\n","        (and then corressponding weights/biases)\n","        1. this function is called when entire output sequence is obtained\n","        2. iterate this function from the last state to the first\n","        3. reduced repition of calculation\n","    '''\n","    def top_diff_is(self, top_diff_h, top_diff_s):\n","        # notice that top_diff_s is carried along the constant error carousel\n","        ds = self.state.o * top_diff_h + top_diff_s\n","        do = self.state.s * top_diff_h\n","        di = self.state.g * ds\n","        dg = self.state.i * ds\n","        df = self.s_prev * ds\n","\n","\n","        # diffs w.r.t. vector inside sigma / tanh function\n","        di_input = sigmoid_derivative(self.state.i) * di \n","        df_input = sigmoid_derivative(self.state.f) * df \n","        do_input = sigmoid_derivative(self.state.o) * do \n","        dg_input = tanh_derivative(self.state.g) * dg\n","\n","        # diffs w.r.t. inputs\n","        self.param.wi_diff += np.outer(di_input, self.xc)\n","        self.param.wf_diff += np.outer(df_input, self.xc)\n","        self.param.wo_diff += np.outer(do_input, self.xc)\n","        self.param.wg_diff += np.outer(dg_input, self.xc)\n","        self.param.bi_diff += di_input\n","        self.param.bf_diff += df_input       \n","        self.param.bo_diff += do_input\n","        self.param.bg_diff += dg_input       \n","\n","        # compute bottom diff\n","        dxc = np.zeros_like(self.xc)\n","        dxc += np.dot(self.param.wi.T, di_input)\n","        dxc += np.dot(self.param.wf.T, df_input)\n","        dxc += np.dot(self.param.wo.T, do_input)\n","        dxc += np.dot(self.param.wg.T, dg_input)\n","\n","        # save bottom diffs\n","        self.state.bottom_diff_s = ds * self.state.f\n","        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n","\n"],"metadata":{"id":"848JCp64foVG","executionInfo":{"status":"ok","timestamp":1684711820637,"user_tz":-120,"elapsed":20,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["class LstmNetwork():\n","    def __init__(self, lstm_param):\n","        self.lstm_param = lstm_param\n","        self.lstm_node_list = []\n","        # input sequence\n","        self.x_list = []\n","\n","\n","\n","    ''' BPTT method: straightforward implementation\n","          no optimized as original method,\n","          but natural to consider,\n","          and importantly suitable for migration to [FPTT]  \n","\n","        idea:\n","        at each time step, the pair of output and label result in a loss\n","        the loss depends on all previous [h], can be truncated\n","        each [h] depends on all previous [s], can be truncated\n","\n","\n","    '''\n","    def backward(self, y, loss_layer, trunc_h= None, trunc_s= None):\n","\n","        assert len(y) == len(self.x_list)\n","\n","        # gradient of l(t) w.r.t. h(t), h(t-1), ..., h(0)\n","        dh = np.zeros((len(self.x_list), self.lstm_param.mem_cell_ct))\n","        # gradient of l(t) w.r.t. h(t), h(t-1), ..., h(0) w.r.t. s(t), s(t-1), ..., s(0)\n","        ds = np.zeros((len(self.x_list), self.lstm_param.mem_cell_ct))\n","\n","        loss = 0.\n","\n","        for t in range (len(self.x_list)):\n","\n","            loss += loss_layer.loss(self.lstm_node_list[t].state.h, y[t])\n","            dh[t] = loss_layer.bottom_diff(self.lstm_node_list[t].state.h, y[t])\n","\n","            # starting point of [h] (oldest) to access \n","            h_sp = 0 if trunc_h is None else max(0, t-trunc_h)\n","            for h_step in np.arange(h_sp, t+1)[::-1]:\n","\n","                ds[t] = self.lstm_node_list[h_step].state.o * dh[t] \n","\n","                do = self.lstm_node_list[h_step].state.s * dh[t]\n","                do_input = sigmoid_derivative(self.lstm_node_list[h_step].state.o) * do \n","                self.lstm_param.wo_diff += np.outer(do_input, self.lstm_node_list[h_step].xc)\n","                self.lstm_param.bo_diff += do_input\n","                \n","                \n","                s_sp = 0 if trunc_s is None else max(0, h_step -trunc_s)\n","                for s_step in np.arange(s_sp, h_step+1)[::-1]:\n","                    di = self.lstm_node_list[s_step].state.g * ds[t]\n","                    # df = (0. * ds[t]) if s_step==0 else (self.lstm_node_list[s_step-1].state.s * ds[t])\n","                    df = self.lstm_node_list[s_step].s_prev * ds[t]\n","                    dg = self.lstm_node_list[s_step].state.i * ds[t]\n","\n","                    di_input = sigmoid_derivative(self.lstm_node_list[s_step].state.i) * di \n","                    df_input = sigmoid_derivative(self.lstm_node_list[s_step].state.f) * df \n","                    dg_input = tanh_derivative(self.lstm_node_list[s_step].state.g) * dg\n","\n","                    self.lstm_param.wi_diff += np.outer(di_input, self.lstm_node_list[s_step].xc)\n","                    self.lstm_param.wf_diff += np.outer(df_input, self.lstm_node_list[s_step].xc)\n","                    self.lstm_param.wg_diff += np.outer(dg_input, self.lstm_node_list[s_step].xc)\n","                    self.lstm_param.bi_diff += di_input\n","                    self.lstm_param.bf_diff += df_input       \n","                    self.lstm_param.bg_diff += dg_input       \n","\n","                    ds[t] = ds[t] * self.lstm_node_list[s_step].state.f\n","                    \n","                    if s_step == h_step: \n","                        dxc = np.zeros_like(self.lstm_node_list[s_step].xc)\n","                        dxc += np.dot(self.lstm_param.wi.T, di_input)\n","                        dxc += np.dot(self.lstm_param.wf.T, df_input)\n","                        dxc += np.dot(self.lstm_param.wo.T, do_input)\n","                        dxc += np.dot(self.lstm_param.wg.T, dg_input)\n","                        dh[t] = dxc[self.lstm_param.x_dim:]\n","\n","        return loss\n","\n","    def backward_one_time_step(self, y_label, loss_layer, t, trunc_h= None, trunc_s= None):\n","\n","        # gradient of l(t) w.r.t. h(t), h(t-1), ..., h(0)\n","        dh = np.zeros((self.lstm_param.mem_cell_ct))\n","        # gradient of l(t) w.r.t. h(t), h(t-1), ..., h(0) w.r.t. s(t), s(t-1), ..., s(0)\n","        ds = np.zeros((self.lstm_param.mem_cell_ct))\n","\n","        loss = loss_layer.loss(self.lstm_node_list[t].state.h, y_label) \n","        dh = loss_layer.bottom_diff(self.lstm_node_list[t].state.h, y_label)\n","\n","        # starting point of [h] (oldest) to access \n","        h_sp = 0 if trunc_h is None else max(0, t-trunc_h)\n","        for h_step in np.arange(h_sp, t+1)[::-1]:\n","\n","            ds = self.lstm_node_list[h_step].state.o * dh\n","\n","            do = self.lstm_node_list[h_step].state.s * dh\n","            do_input = sigmoid_derivative(self.lstm_node_list[h_step].state.o) * do \n","            self.lstm_param.wo_diff += np.outer(do_input, self.lstm_node_list[h_step].xc)\n","            self.lstm_param.bo_diff += do_input\n","            \n","            \n","            s_sp = 0 if trunc_s is None else max(0, h_step -trunc_s)\n","            for s_step in np.arange(s_sp, h_step+1)[::-1]:\n","                di = self.lstm_node_list[s_step].state.g * ds\n","                df = self.lstm_node_list[s_step].s_prev * ds\n","                dg = self.lstm_node_list[s_step].state.i * ds\n","\n","                di_input = sigmoid_derivative(self.lstm_node_list[s_step].state.i) * di \n","                df_input = sigmoid_derivative(self.lstm_node_list[s_step].state.f) * df \n","                dg_input = tanh_derivative(self.lstm_node_list[s_step].state.g) * dg\n","\n","                self.lstm_param.wi_diff += np.outer(di_input, self.lstm_node_list[s_step].xc)\n","                self.lstm_param.wf_diff += np.outer(df_input, self.lstm_node_list[s_step].xc)\n","                self.lstm_param.wg_diff += np.outer(dg_input, self.lstm_node_list[s_step].xc)\n","                self.lstm_param.bi_diff += di_input\n","                self.lstm_param.bf_diff += df_input       \n","                self.lstm_param.bg_diff += dg_input       \n","\n","                ds= ds* self.lstm_node_list[s_step].state.f\n","                \n","                if s_step == h_step: \n","                    dxc = np.zeros_like(self.lstm_node_list[s_step].xc)\n","                    dxc += np.dot(self.lstm_param.wi.T, di_input)\n","                    dxc += np.dot(self.lstm_param.wf.T, df_input)\n","                    dxc += np.dot(self.lstm_param.wo.T, do_input)\n","                    dxc += np.dot(self.lstm_param.wg.T, dg_input)\n","                    dh = dxc[self.lstm_param.x_dim:]\n","\n","        return loss\n","\n","\n","\n","\n","    def y_list_is(self, y_list, loss_layer):\n","        \"\"\"\n","        Updates diffs by setting target sequence \n","        with corresponding loss layer. \n","        Will *NOT* update parameters.  To update parameters,\n","        call self.lstm_param.apply_diff()\n","        \"\"\"\n","        assert len(y_list) == len(self.x_list)\n","        idx = len(self.x_list) - 1\n","        # first node only gets diffs from label ...\n","        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n","        diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n","        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n","        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n","        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n","        idx -= 1\n","\n","        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n","        ### we also propagate error along constant error carousel using diff_s\n","        while idx >= 0:\n","            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n","            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n","            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n","            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n","            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n","            idx -= 1 \n","\n","        return loss\n","\n","    def x_list_clear(self):\n","        self.x_list = []\n","\n","    def x_list_add(self, x):\n","        self.x_list.append(x)\n","        if len(self.x_list) > len(self.lstm_node_list):\n","            # need to add new lstm node, create new state mem\n","            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n","            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n","\n","        # get index of most recent x input\n","        idx = len(self.x_list) - 1\n","        if idx == 0:\n","            # no recurrent inputs yet\n","            self.lstm_node_list[idx].bottom_data_is(x)\n","        else:\n","            s_prev = self.lstm_node_list[idx - 1].state.s\n","            h_prev = self.lstm_node_list[idx - 1].state.h\n","            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n","\n"],"metadata":{"id":"5bsNv_nJZUGv","executionInfo":{"status":"ok","timestamp":1684711820637,"user_tz":-120,"elapsed":20,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["class ToyLossLayer:\n","    \"\"\"\n","    Computes square loss with first element of hidden layer array.\n","    \"\"\"\n","    @classmethod\n","    def loss(self, pred, label):\n","        return sum((pred - label) ** 2)\n","\n","    @classmethod\n","    def bottom_diff(self, pred, label):\n","        diff =  2 * (pred - label)\n","        return diff"],"metadata":{"id":"K-XKiuGEfskV","executionInfo":{"status":"ok","timestamp":1684711820638,"user_tz":-120,"elapsed":20,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def bptt(trunc_s=None, trunc_h=None):\n","    # learns to repeat simple sequence from random inputs\n","    lossList = []\n","    # np.random.seed(0)\n","    np.random.seed(1)\n","\n","    # parameters for input data dimension and lstm cell count\n","    mem_cell_ct = 100\n","    x_dim = 50\n","    lstm_param = LstmParam(mem_cell_ct, x_dim)\n","    lstm_net = LstmNetwork(lstm_param)\n","\n","\n","    y_list = [-0.5, 0.2, 0.3, 0.1, 0.4, 0.7, 0.2, 0.6, 0.1, -0.5]\n","    # y_list = [-0.5, 0.2, 0.1, -0.5]\n","    y = np.zeros((len(y_list), mem_cell_ct))\n","    for i in range(len(y_list)):\n","        y[i][0] = y_list[i]\n","\n","\n","\n","\n","    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n","\n","    # print(input_val_arr)\n","\n","\n","    for cur_iter in range(100):\n","        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n","        for ind in range(len(y_list)):\n","            lstm_net.x_list_add(input_val_arr[ind])\n","\n","        print(\"y_pred = [\" +\n","              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n","              \"]\", end=\", \")\n","\n","        # if cur_iter == 1:\n","            # print(lstm_net.lstm_node_list[ind].param.wi.shape)\n","\n","        # print(\"% 2.5f, %2.5f\" % (lstm_net.lstm_node_list[ind].param.wi[1][0],lstm_net.lstm_node_list[ind].param.wi[1][1]))\n","\n","        # loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n","        loss = lstm_net.backward(y, ToyLossLayer, trunc_s=trunc_s, trunc_h=trunc_h)\n","        lossList.append(loss)\n","        print(\"loss:\", \"%.3e\" % loss)\n","        lstm_param.apply_diff(lr=0.1)\n","        lstm_net.x_list_clear()\n","    \n","    return lossList"],"metadata":{"id":"1E-6xX2rfsYl","executionInfo":{"status":"ok","timestamp":1684711820638,"user_tz":-120,"elapsed":19,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["def bptt_online(fptt=False):\n","    # learns to repeat simple sequence from random inputs\n","    lossList = []\n","    # np.random.seed(0)\n","    np.random.seed(1)\n","\n","    # parameters for input data dimension and lstm cell count\n","    mem_cell_ct = 100\n","    x_dim = 50\n","    lstm_param = LstmParam(mem_cell_ct, x_dim)\n","    lstm_net = LstmNetwork(lstm_param)\n","\n","\n","    y_list = [-0.5, 0.2, 0.3, 0.1, 0.4, 0.7, 0.2, 0.6, 0.1, -0.5, -0.5, 0.2, 0.3, 0.1, 0.4, 0.7, 0.2, 0.6, 0.1, -0.5]\n","    # y_list = [-0.5, 0.2, 0.1, -0.5]\n","    y = np.zeros((len(y_list), mem_cell_ct))\n","    for i in range(len(y_list)):\n","        y[i][0] = y_list[i]\n","    \n","    \n","    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n","\n","    # print(input_val_arr)\n","\n","\n","    for cur_iter in range(100):\n","        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n","        for ind in range(len(y_list)):\n","            lstm_net.x_list_add(input_val_arr[ind])\n","            loss = lstm_net.backward_one_time_step(y[ind], ToyLossLayer, ind, trunc_s=0, trunc_h=0)\n","            if fptt is False:\n","                lstm_param.apply_diff(lr=0.1)\n","            else:\n","                lstm_param.apply_diff_fptt(lr=0.1)\n","\n","        print(\"y_pred = [\" +\n","              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n","              \"]\", end=\", \")\n","\n","        lossList.append(loss)\n","        print(\"loss:\", \"%.3e\" % loss)\n","        lstm_net.x_list_clear()\n","    \n","    return lossList"],"metadata":{"executionInfo":{"status":"ok","timestamp":1684711820639,"user_tz":-120,"elapsed":19,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}},"id":"1LHupzO1-Sc9"},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["llst = []\n","llst = bptt()\n","\n","llst1 = []\n","llst1 = bptt(trunc_s=0, trunc_h=0)"],"metadata":{"id":"AFh4wg7pf6E8","executionInfo":{"status":"ok","timestamp":1684711830561,"user_tz":-120,"elapsed":9940,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"29b8fc70-ca71-4cba-85bb-9ab483fb9ce4"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["iter  0: y_pred = [ 0.04135,  0.06930,  0.11699,  0.16562,  0.12990,  0.07803,  0.05470,  0.14010,  0.12658,  0.10166], loss: 1.808e+01\n","iter  1: y_pred = [ 0.30533,  0.55675,  0.81080,  1.03841,  0.99479,  0.96655,  1.00036,  1.18529,  1.12651,  1.08277], loss: 5.851e+01\n","iter  2: y_pred = [-0.00000,  0.00000,  0.00001,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.145e+01\n","iter  3: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000, -0.00000,  0.00000, -0.00000, -0.00000], loss: 5.507e+00\n","iter  4: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 3.623e+00\n","iter  5: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.732e+00\n","iter  6: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.433e+00\n","iter  7: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.303e+00\n","iter  8: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.221e+00\n","iter  9: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.162e+00\n","iter 10: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.117e+00\n","iter 11: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.082e+00\n","iter 12: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.052e+00\n","iter 13: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.027e+00\n","iter 14: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 2.006e+00\n","iter 15: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.988e+00\n","iter 16: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.972e+00\n","iter 17: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.958e+00\n","iter 18: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.945e+00\n","iter 19: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.933e+00\n","iter 20: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.923e+00\n","iter 21: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.914e+00\n","iter 22: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.905e+00\n","iter 23: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.897e+00\n","iter 24: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.890e+00\n","iter 25: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.883e+00\n","iter 26: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.877e+00\n","iter 27: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.871e+00\n","iter 28: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.866e+00\n","iter 29: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.861e+00\n","iter 30: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.856e+00\n","iter 31: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.851e+00\n","iter 32: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.847e+00\n","iter 33: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.843e+00\n","iter 34: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.839e+00\n","iter 35: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.836e+00\n","iter 36: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.832e+00\n","iter 37: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.829e+00\n","iter 38: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.826e+00\n","iter 39: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.823e+00\n","iter 40: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.820e+00\n","iter 41: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.817e+00\n","iter 42: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.815e+00\n","iter 43: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.812e+00\n","iter 44: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.810e+00\n","iter 45: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.808e+00\n","iter 46: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.806e+00\n","iter 47: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.803e+00\n","iter 48: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.801e+00\n","iter 49: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.799e+00\n","iter 50: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.798e+00\n","iter 51: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.796e+00\n","iter 52: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.794e+00\n","iter 53: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.792e+00\n","iter 54: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.791e+00\n","iter 55: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.789e+00\n","iter 56: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.788e+00\n","iter 57: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.786e+00\n","iter 58: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.785e+00\n","iter 59: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.784e+00\n","iter 60: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.782e+00\n","iter 61: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.781e+00\n","iter 62: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.780e+00\n","iter 63: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.779e+00\n","iter 64: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.777e+00\n","iter 65: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.776e+00\n","iter 66: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.775e+00\n","iter 67: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.774e+00\n","iter 68: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.773e+00\n","iter 69: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.772e+00\n","iter 70: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.771e+00\n","iter 71: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.770e+00\n","iter 72: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.769e+00\n","iter 73: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.768e+00\n","iter 74: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.767e+00\n","iter 75: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.767e+00\n","iter 76: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.766e+00\n","iter 77: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.765e+00\n","iter 78: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.764e+00\n","iter 79: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.763e+00\n","iter 80: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.763e+00\n","iter 81: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.762e+00\n","iter 82: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.761e+00\n","iter 83: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.760e+00\n","iter 84: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.760e+00\n","iter 85: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.759e+00\n","iter 86: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.758e+00\n","iter 87: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.758e+00\n","iter 88: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.757e+00\n","iter 89: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.756e+00\n","iter 90: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.756e+00\n","iter 91: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.755e+00\n","iter 92: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.755e+00\n","iter 93: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.754e+00\n","iter 94: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.753e+00\n","iter 95: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.753e+00\n","iter 96: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.752e+00\n","iter 97: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.752e+00\n","iter 98: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.751e+00\n","iter 99: y_pred = [-0.00000,  0.00000,  0.00000,  0.00000,  0.00001, -0.00000,  0.00000,  0.00000, -0.00000, -0.00000], loss: 1.751e+00\n","iter  0: y_pred = [ 0.04135,  0.06930,  0.11699,  0.16562,  0.12990,  0.07803,  0.05470,  0.14010,  0.12658,  0.10166], loss: 1.808e+01\n","iter  1: y_pred = [ 0.11493,  0.24060,  0.37838,  0.51096,  0.46404,  0.42463,  0.42307,  0.58901,  0.53532,  0.43053], loss: 3.428e+01\n","iter  2: y_pred = [-0.10747, -0.18216, -0.22566, -0.21096, -0.23303, -0.19089, -0.18878, -0.23621, -0.21533, -0.16661], loss: 1.602e+01\n","iter  3: y_pred = [-0.01661, -0.03354, -0.04182, -0.02785, -0.04422, -0.02829, -0.03066, -0.02921, -0.03597, -0.02847], loss: 5.258e+00\n","iter  4: y_pred = [-0.01260, -0.02349, -0.02775, -0.01776, -0.02866, -0.01797, -0.02016, -0.01705, -0.02335, -0.01972], loss: 3.379e+00\n","iter  5: y_pred = [-0.01045, -0.01869, -0.02131, -0.01362, -0.02155, -0.01380, -0.01574, -0.01145, -0.01819, -0.01678], loss: 2.848e+00\n","iter  6: y_pred = [-0.00890, -0.01465, -0.01577, -0.01012, -0.01538, -0.01029, -0.01198, -0.00688, -0.01345, -0.01411], loss: 2.186e+00\n","iter  7: y_pred = [-0.00774, -0.01144, -0.01128, -0.00740, -0.01036, -0.00754, -0.00904, -0.00324, -0.00976, -0.01223], loss: 2.112e+00\n","iter  8: y_pred = [-0.00676, -0.00854, -0.00719, -0.00496, -0.00578, -0.00508, -0.00639, -0.00002, -0.00641, -0.01062], loss: 2.051e+00\n","iter  9: y_pred = [-0.00588, -0.00580, -0.00328, -0.00266, -0.00136, -0.00275, -0.00389,  0.00307, -0.00322, -0.00923], loss: 2.008e+00\n","iter 10: y_pred = [-0.00502, -0.00313,  0.00050, -0.00041,  0.00282, -0.00051, -0.00149,  0.00592, -0.00019, -0.00790], loss: 1.968e+00\n","iter 11: y_pred = [-0.00415, -0.00033,  0.00455,  0.00201,  0.00741,  0.00194,  0.00114,  0.00915,  0.00315, -0.00654], loss: 1.939e+00\n","iter 12: y_pred = [-0.00320,  0.00253,  0.00859,  0.00448,  0.01182,  0.00437,  0.00369,  0.01225,  0.00637, -0.00517], loss: 1.902e+00\n","iter 13: y_pred = [-0.00213,  0.00581,  0.01330,  0.00744,  0.01713,  0.00733,  0.00682,  0.01623,  0.01032, -0.00356], loss: 1.866e+00\n","iter 14: y_pred = [-0.00087,  0.00943,  0.01846,  0.01080,  0.02276,  0.01060,  0.01017,  0.02060,  0.01454, -0.00180], loss: 1.827e+00\n","iter 15: y_pred = [ 0.00069,  0.01388,  0.02487,  0.01512,  0.02984,  0.01484,  0.01449,  0.02651,  0.01997,  0.00044], loss: 1.790e+00\n","iter 16: y_pred = [ 0.00270,  0.01941,  0.03281,  0.02076,  0.03851,  0.02028,  0.01988,  0.03419,  0.02672,  0.00324], loss: 1.749e+00\n","iter 17: y_pred = [ 0.00545,  0.02677,  0.04342,  0.02871,  0.05010,  0.02792,  0.02731,  0.04520,  0.03595,  0.00707], loss: 1.702e+00\n","iter 18: y_pred = [ 0.00938,  0.03693,  0.05808,  0.04044,  0.06604,  0.03909,  0.03789,  0.06146,  0.04895,  0.01240], loss: 1.642e+00\n","iter 19: y_pred = [ 0.01512,  0.05153,  0.07911,  0.05856,  0.08894,  0.05633,  0.05378,  0.08675,  0.06815,  0.02006], loss: 1.562e+00\n","iter 20: y_pred = [ 0.02314,  0.07241,  0.10936,  0.08703,  0.12214,  0.08357,  0.07802,  0.12681,  0.09686,  0.03045], loss: 1.453e+00\n","iter 21: y_pred = [ 0.03141,  0.09927,  0.14934,  0.12891,  0.16743,  0.12469,  0.11301,  0.18773,  0.13722,  0.04047], loss: 1.315e+00\n","iter 22: y_pred = [ 0.02700,  0.12026,  0.18647,  0.17481,  0.21508,  0.17401,  0.15182,  0.26420,  0.18027,  0.03336], loss: 1.157e+00\n","iter 23: y_pred = [-0.02024,  0.10539,  0.18717,  0.18902,  0.23527,  0.20350,  0.16862,  0.32711,  0.19634, -0.02388], loss: 9.772e-01\n","iter 24: y_pred = [-0.09710,  0.08036,  0.18016,  0.19131,  0.25428,  0.24151,  0.18656,  0.40075,  0.21037, -0.10665], loss: 7.655e-01\n","iter 25: y_pred = [-0.16532,  0.09498,  0.21743,  0.22832,  0.31498,  0.34479,  0.24686,  0.51849,  0.26327, -0.17426], loss: 5.458e-01\n","iter 26: y_pred = [-0.34825, -0.06056,  0.03082, -0.02824,  0.13949,  0.20428,  0.07842,  0.38351,  0.06608, -0.38572], loss: 6.937e-01\n","iter 27: y_pred = [ 0.51947,  0.73058,  0.87288,  0.90798,  0.89878,  0.98375,  0.81246,  1.06055,  0.88016,  0.73114], loss: 5.534e+00\n","iter 28: y_pred = [-0.00366,  0.00705,  0.00774,  0.00187,  0.01345,  0.00939,  0.00399,  0.01359,  0.00240, -0.00609], loss: 1.861e+00\n","iter 29: y_pred = [-0.00384,  0.00855,  0.00957,  0.00253,  0.01577,  0.01123,  0.00498,  0.01576,  0.00338, -0.00674], loss: 1.759e+00\n","iter 30: y_pred = [-0.00406,  0.01040,  0.01171,  0.00334,  0.01840,  0.01346,  0.00615,  0.01842,  0.00453, -0.00753], loss: 1.729e+00\n","iter 31: y_pred = [-0.00431,  0.01280,  0.01453,  0.00445,  0.02190,  0.01649,  0.00773,  0.02202,  0.00608, -0.00859], loss: 1.705e+00\n","iter 32: y_pred = [-0.00461,  0.01596,  0.01816,  0.00595,  0.02632,  0.02050,  0.00977,  0.02682,  0.00808, -0.00999], loss: 1.680e+00\n","iter 33: y_pred = [-0.00496,  0.02032,  0.02315,  0.00814,  0.03235,  0.02621,  0.01264,  0.03366,  0.01089, -0.01196], loss: 1.647e+00\n","iter 34: y_pred = [-0.00540,  0.02661,  0.03022,  0.01145,  0.04077,  0.03463,  0.01679,  0.04374,  0.01494, -0.01484], loss: 1.604e+00\n","iter 35: y_pred = [-0.00597,  0.03623,  0.04087,  0.01684,  0.05324,  0.04788,  0.02322,  0.05953,  0.02116, -0.01938], loss: 1.539e+00\n","iter 36: y_pred = [-0.00689,  0.05186,  0.05781,  0.02626,  0.07269,  0.07004,  0.03380,  0.08585,  0.03128, -0.02718], loss: 1.439e+00\n","iter 37: y_pred = [-0.00920,  0.07882,  0.08616,  0.04407,  0.10459,  0.10942,  0.05238,  0.13230,  0.04865, -0.04217], loss: 1.276e+00\n","iter 38: y_pred = [-0.01850,  0.12586,  0.13340,  0.07867,  0.15706,  0.17977,  0.08560,  0.21474,  0.07811, -0.07486], loss: 1.019e+00\n","iter 39: y_pred = [-0.06181,  0.19498,  0.19725,  0.13464,  0.23079,  0.28502,  0.13588,  0.33923,  0.11617, -0.14935], loss: 6.788e-01\n","iter 40: y_pred = [-0.18987,  0.24683,  0.23321,  0.17114,  0.29159,  0.37288,  0.17333,  0.45697,  0.12220, -0.27984], loss: 3.739e-01\n","iter 41: y_pred = [-0.31384,  0.27270,  0.24501,  0.17646,  0.33121,  0.43043,  0.19143,  0.53288,  0.10842, -0.39453], loss: 2.178e-01\n","iter 42: y_pred = [-0.37528,  0.29132,  0.26232,  0.17946,  0.36135,  0.48292,  0.20635,  0.57738,  0.10982, -0.45560], loss: 1.572e-01\n","iter 43: y_pred = [-0.43374,  0.26498,  0.24046,  0.13146,  0.35708,  0.49449,  0.18398,  0.58497,  0.07479, -0.49889], loss: 1.312e-01\n","iter 44: y_pred = [-0.38963,  0.33152,  0.32450,  0.21872,  0.41464,  0.57713,  0.25036,  0.63236,  0.16004, -0.48779], loss: 1.383e-01\n","iter 45: y_pred = [-0.54020,  0.08411,  0.08364, -0.09391,  0.25507,  0.40648,  0.03755,  0.50722, -0.09230, -0.56151], loss: 3.561e-01\n","iter 46: y_pred = [ 0.42677,  0.55260,  0.57658,  0.51922,  0.56605,  0.71716,  0.46234,  0.71094,  0.48784,  0.17071], loss: 2.033e+00\n","iter 47: y_pred = [-0.26456, -0.07290, -0.06555, -0.09328,  0.05355,  0.08767, -0.03034,  0.21542, -0.10318, -0.27031], loss: 1.193e+00\n","iter 48: y_pred = [ 0.06516,  0.30887,  0.32983,  0.22682,  0.34725,  0.48678,  0.22169,  0.46357,  0.23606, -0.13335], loss: 6.502e-01\n","iter 49: y_pred = [-0.27478,  0.23443,  0.24088,  0.15186,  0.30637,  0.46069,  0.17237,  0.46006,  0.12950, -0.31980], loss: 2.443e-01\n","iter 50: y_pred = [-0.37442,  0.28721,  0.28788,  0.19422,  0.36785,  0.54596,  0.21788,  0.55193,  0.15200, -0.42250], loss: 1.307e-01\n","iter 51: y_pred = [-0.43892,  0.25682,  0.25740,  0.15297,  0.36302,  0.54961,  0.20025,  0.56708,  0.10477, -0.47121], loss: 9.763e-02\n","iter 52: y_pred = [-0.46515,  0.26962,  0.27604,  0.16173,  0.38258,  0.57862,  0.21372,  0.59178,  0.11265, -0.49898], loss: 8.466e-02\n","iter 53: y_pred = [-0.48599,  0.24598,  0.26036,  0.13242,  0.37625,  0.57919,  0.19953,  0.59314,  0.08812, -0.51416], loss: 7.795e-02\n","iter 54: y_pred = [-0.48843,  0.26375,  0.28624,  0.15190,  0.39328,  0.60322,  0.21586,  0.60787,  0.11003, -0.52061], loss: 7.359e-02\n","iter 55: y_pred = [-0.50131,  0.22880,  0.26080,  0.11262,  0.37770,  0.59378,  0.19288,  0.59930,  0.07838, -0.52646], loss: 7.060e-02\n","iter 56: y_pred = [-0.49148,  0.26534,  0.30287,  0.15516,  0.40302,  0.62349,  0.22240,  0.61691,  0.12118, -0.52491], loss: 6.904e-02\n","iter 57: y_pred = [-0.50817,  0.20451,  0.25286,  0.08796,  0.37131,  0.59846,  0.18017,  0.59634,  0.06423, -0.52937], loss: 6.903e-02\n","iter 58: y_pred = [-0.48212,  0.28052,  0.32842,  0.17512,  0.41706,  0.64431,  0.23740,  0.62585,  0.14658, -0.52096], loss: 7.319e-02\n","iter 59: y_pred = [-0.51139,  0.17021,  0.23300,  0.05407,  0.35614,  0.59305,  0.15899,  0.58484,  0.04044, -0.52718], loss: 7.829e-02\n","iter 60: y_pred = [-0.45518,  0.31290,  0.36478,  0.21427,  0.43687,  0.66646,  0.26222,  0.63555,  0.18880, -0.50764], loss: 9.793e-02\n","iter 61: y_pred = [-0.50583,  0.13695,  0.21052,  0.02378,  0.33695,  0.58151,  0.13649,  0.56608,  0.01737, -0.51625], loss: 9.808e-02\n","iter 62: y_pred = [-0.41822,  0.33974,  0.39150,  0.24465,  0.44973,  0.67981,  0.27923,  0.63763,  0.22272, -0.48671], loss: 1.306e-01\n","iter 63: y_pred = [-0.49078,  0.13519,  0.21304,  0.02681,  0.33277,  0.58133,  0.13448,  0.55428,  0.02095, -0.49860], loss: 9.709e-02\n","iter 64: y_pred = [-0.42194,  0.32561,  0.38098,  0.22677,  0.44083,  0.67614,  0.26656,  0.62715,  0.20819, -0.48129], loss: 1.113e-01\n","iter 65: y_pred = [-0.48843,  0.14957,  0.23029,  0.04190,  0.34340,  0.59584,  0.14538,  0.55912,  0.03478, -0.49595], loss: 8.029e-02\n","iter 66: y_pred = [-0.44327,  0.30175,  0.36353,  0.19915,  0.43051,  0.67250,  0.25049,  0.61992,  0.18240, -0.48825], loss: 8.403e-02\n","iter 67: y_pred = [-0.49469,  0.15836,  0.24320,  0.05026,  0.35396,  0.61083,  0.15424,  0.56800,  0.04289, -0.50198], loss: 6.810e-02\n","iter 68: y_pred = [-0.45735,  0.28717,  0.35465,  0.18299,  0.42640,  0.67370,  0.24251,  0.61813,  0.16776, -0.49471], loss: 7.048e-02\n","iter 69: y_pred = [-0.49973,  0.16170,  0.25066,  0.05395,  0.36054,  0.62149,  0.15943,  0.57381,  0.04721, -0.50641], loss: 6.124e-02\n","iter 70: y_pred = [-0.46501,  0.27838,  0.35027,  0.17377,  0.42473,  0.67622,  0.23849,  0.61755,  0.16018, -0.49814], loss: 6.328e-02\n","iter 71: y_pred = [-0.50250,  0.16304,  0.25544,  0.05612,  0.36469,  0.62925,  0.16278,  0.57714,  0.05035, -0.50842], loss: 5.671e-02\n","iter 72: y_pred = [-0.46953,  0.27189,  0.34725,  0.16728,  0.42355,  0.67862,  0.23570,  0.61687,  0.15534, -0.49969], loss: 5.831e-02\n","iter 73: y_pred = [-0.50392,  0.16406,  0.25915,  0.05806,  0.36780,  0.63552,  0.16545,  0.57935,  0.05330, -0.50911], loss: 5.307e-02\n","iter 74: y_pred = [-0.47278,  0.26624,  0.34449,  0.16173,  0.42234,  0.68063,  0.23323,  0.61598,  0.15135, -0.50043], loss: 5.419e-02\n","iter 75: y_pred = [-0.50471,  0.16529,  0.26244,  0.06011,  0.37049,  0.64100,  0.16792,  0.58112,  0.05627, -0.50926], loss: 4.985e-02\n","iter 76: y_pred = [-0.47552,  0.26097,  0.34170,  0.15661,  0.42107,  0.68231,  0.23086,  0.61501,  0.14765, -0.50089], loss: 5.054e-02\n","iter 77: y_pred = [-0.50521,  0.16674,  0.26547,  0.06227,  0.37297,  0.64594,  0.17029,  0.58273,  0.05925, -0.50921], loss: 4.692e-02\n","iter 78: y_pred = [-0.47798,  0.25601,  0.33893,  0.15181,  0.41979,  0.68376,  0.22859,  0.61405,  0.14413, -0.50124], loss: 4.727e-02\n","iter 79: y_pred = [-0.50554,  0.16834,  0.26827,  0.06445,  0.37527,  0.65045,  0.17255,  0.58423,  0.06215, -0.50907], loss: 4.426e-02\n","iter 80: y_pred = [-0.48020,  0.25141,  0.33623,  0.14737,  0.41853,  0.68504,  0.22646,  0.61314,  0.14082, -0.50153], loss: 4.435e-02\n","iter 81: y_pred = [-0.50575,  0.17001,  0.27084,  0.06660,  0.37740,  0.65455,  0.17469,  0.58563,  0.06492, -0.50888], loss: 4.185e-02\n","iter 82: y_pred = [-0.48220,  0.24716,  0.33366,  0.14329,  0.41733,  0.68618,  0.22448,  0.61228,  0.13775, -0.50177], loss: 4.176e-02\n","iter 83: y_pred = [-0.50587,  0.17168,  0.27318,  0.06867,  0.37935,  0.65828,  0.17667,  0.58692,  0.06754, -0.50865], loss: 3.968e-02\n","iter 84: y_pred = [-0.48397,  0.24327,  0.33122,  0.13957,  0.41620,  0.68721,  0.22265,  0.61149,  0.13492, -0.50195], loss: 3.946e-02\n","iter 85: y_pred = [-0.50590,  0.17332,  0.27531,  0.07065,  0.38112,  0.66166,  0.17851,  0.58810,  0.07000, -0.50838], loss: 3.772e-02\n","iter 86: y_pred = [-0.48555,  0.23971,  0.32895,  0.13620,  0.41513,  0.68815,  0.22096,  0.61076,  0.13232, -0.50208], loss: 3.741e-02\n","iter 87: y_pred = [-0.50586,  0.17492,  0.27725,  0.07253,  0.38274,  0.66473,  0.18020,  0.58918,  0.07228, -0.50808], loss: 3.596e-02\n","iter 88: y_pred = [-0.48694,  0.23647,  0.32682,  0.13313,  0.41413,  0.68901,  0.21941,  0.61008,  0.12994, -0.50216], loss: 3.558e-02\n","iter 89: y_pred = [-0.50576,  0.17645,  0.27901,  0.07430,  0.38420,  0.66752,  0.18176,  0.59016,  0.07440, -0.50776], loss: 3.435e-02\n","iter 90: y_pred = [-0.48818,  0.23352,  0.32484,  0.13034,  0.41320,  0.68979,  0.21798,  0.60944,  0.12774, -0.50220], loss: 3.394e-02\n","iter 91: y_pred = [-0.50562,  0.17792,  0.28061,  0.07598,  0.38553,  0.67006,  0.18319,  0.59105,  0.07636, -0.50743], loss: 3.290e-02\n","iter 92: y_pred = [-0.48928,  0.23083,  0.32301,  0.12782,  0.41232,  0.69051,  0.21667,  0.60885,  0.12573, -0.50221], loss: 3.247e-02\n","iter 93: y_pred = [-0.50545,  0.17932,  0.28208,  0.07755,  0.38674,  0.67238,  0.18450,  0.59186,  0.07817, -0.50708], loss: 3.157e-02\n","iter 94: y_pred = [-0.49025,  0.22837,  0.32131,  0.12552,  0.41151,  0.69117,  0.21545,  0.60830,  0.12387, -0.50219], loss: 3.113e-02\n","iter 95: y_pred = [-0.50525,  0.18064,  0.28342,  0.07903,  0.38784,  0.67449,  0.18570,  0.59259,  0.07984, -0.50673], loss: 3.035e-02\n","iter 96: y_pred = [-0.49112,  0.22613,  0.31973,  0.12343,  0.41074,  0.69177,  0.21434,  0.60779,  0.12216, -0.50215], loss: 2.991e-02\n","iter 97: y_pred = [-0.50504,  0.18190,  0.28465,  0.08041,  0.38884,  0.67642,  0.18680,  0.59326,  0.08138, -0.50639], loss: 2.923e-02\n","iter 98: y_pred = [-0.49189,  0.22408,  0.31827,  0.12152,  0.41003,  0.69233,  0.21330,  0.60732,  0.12058, -0.50210], loss: 2.880e-02\n","iter 99: y_pred = [-0.50482,  0.18308,  0.28578,  0.08171,  0.38975,  0.67819,  0.18781,  0.59387,  0.08279, -0.50605], loss: 2.820e-02\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(llst1,  label='BPTT')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"loss\")\n","plt.legend(loc='upper right')\n","plt.show()"],"metadata":{"id":"F4x_TM64gKKF","executionInfo":{"status":"ok","timestamp":1684711831003,"user_tz":-120,"elapsed":444,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}},"colab":{"base_uri":"https://localhost:8080/","height":449},"outputId":"ed552927-9cff-4358-d9f3-0616e31e3297"},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["llst2 = []\n","llst2 = bptt_online()\n","\n","\n","llst3 = []\n","llst3 = bptt_online(fptt=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684711836430,"user_tz":-120,"elapsed":5431,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}},"outputId":"a192a473-d1e3-4b3b-cf29-340a72ec9c29","id":"kP4YlBe3GvCI"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["iter  0: y_pred = [ 0.04135, -0.05685, -0.03941,  0.08085,  0.11431,  0.13578,  0.26218,  0.46808,  0.51902,  0.41715,  0.14586,  0.02868, -0.01904, -0.01158,  0.01942,  0.02864,  0.05468,  0.10149,  0.11713,  0.21224], loss: 9.152e-01\n","iter  1: y_pred = [ 0.04473,  0.07616,  0.12454,  0.15600,  0.15277,  0.12918,  0.15914,  0.25802,  0.27151,  0.17939,  0.10985,  0.09120,  0.07052,  0.07685,  0.12363,  0.10889,  0.11492,  0.16154,  0.15236,  0.21202], loss: 7.810e-01\n","iter  2: y_pred = [ 0.05002,  0.09610,  0.15209,  0.17979,  0.17047,  0.15187,  0.17914,  0.28099,  0.28597,  0.15804,  0.09004,  0.09067,  0.07532,  0.08177,  0.14736,  0.13892,  0.13991,  0.20089,  0.17139,  0.19632], loss: 6.798e-01\n","iter  3: y_pred = [ 0.04093,  0.09296,  0.15532,  0.18463,  0.16856,  0.16653,  0.19430,  0.31120,  0.30921,  0.13851,  0.05512,  0.06796,  0.06179,  0.07538,  0.17125,  0.17853,  0.17443,  0.25875,  0.19863,  0.17823], loss: 6.039e-01\n","iter  4: y_pred = [ 0.01240,  0.06493,  0.13888,  0.17630,  0.15585,  0.18484,  0.22033,  0.36371,  0.35015,  0.11339, -0.00567,  0.02087,  0.03965,  0.07428,  0.21906,  0.24793,  0.23072,  0.34188,  0.22552,  0.13360], loss: 5.113e-01\n","iter  5: y_pred = [-0.05572,  0.00170,  0.11384,  0.17257,  0.15384,  0.23360,  0.27482,  0.44531,  0.40038,  0.05823, -0.11125, -0.04254,  0.03670,  0.11327,  0.31733,  0.35063,  0.29336,  0.42228,  0.21268,  0.02774], loss: 3.649e-01\n","iter  6: y_pred = [-0.15422, -0.04553,  0.14524,  0.20135,  0.17261,  0.31213,  0.31953,  0.50383,  0.41223, -0.06204, -0.26045, -0.06416,  0.08887,  0.19659,  0.42833,  0.42966,  0.31648,  0.46618,  0.13757, -0.10897], loss: 2.230e-01\n","iter  7: y_pred = [-0.22802, -0.01354,  0.22090,  0.17824,  0.18576,  0.40048,  0.32457,  0.52120,  0.37897, -0.21841, -0.39712,  0.01015,  0.15169,  0.23005,  0.47255,  0.44497,  0.31459,  0.50202,  0.04125, -0.21601], loss: 1.391e-01\n","iter  8: y_pred = [-0.26309,  0.06059,  0.27388,  0.07867,  0.24327,  0.50790,  0.31359,  0.51716,  0.32289, -0.34387, -0.48325,  0.10339,  0.19788,  0.19815,  0.48364,  0.46361,  0.31081,  0.53321, -0.03748, -0.29826], loss: 9.021e-02\n","iter  9: y_pred = [-0.27706,  0.12393,  0.31590,  0.00370,  0.29531,  0.57666,  0.31272,  0.51546,  0.26633, -0.41445, -0.52514,  0.16045,  0.24955,  0.15342,  0.49618,  0.50409,  0.28626,  0.54979, -0.07491, -0.36283], loss: 6.124e-02\n","iter 10: y_pred = [-0.29934,  0.17140,  0.36408, -0.01308,  0.30744,  0.59886,  0.31034,  0.51686,  0.21919, -0.44952, -0.54276,  0.18998,  0.29458,  0.12697,  0.50445,  0.54126,  0.25957,  0.56275, -0.07921, -0.40755], loss: 4.520e-02\n","iter 11: y_pred = [-0.33999,  0.20567,  0.41141,  0.01236,  0.30131,  0.59882,  0.29343,  0.51993,  0.18791, -0.46577, -0.54854,  0.20464,  0.32390,  0.12082,  0.50552,  0.56758,  0.24216,  0.57144, -0.06768, -0.43544], loss: 3.611e-02\n","iter 12: y_pred = [-0.38750,  0.21943,  0.44108,  0.05636,  0.29708,  0.59720,  0.26397,  0.52140,  0.16985, -0.47260, -0.54702,  0.21362,  0.33938,  0.12351,  0.50279,  0.58946,  0.23192,  0.57499, -0.05004, -0.45169], loss: 3.042e-02\n","iter 13: y_pred = [-0.43146,  0.21474,  0.44564,  0.09249,  0.30760,  0.60652,  0.23241,  0.51733,  0.15686, -0.47532, -0.53970,  0.22140,  0.34689,  0.12640,  0.49933,  0.61136,  0.22594,  0.57558, -0.03037, -0.46138], loss: 2.636e-02\n","iter 14: y_pred = [-0.46829,  0.19901,  0.43114,  0.11494,  0.32919,  0.62538,  0.20936,  0.50877,  0.14226, -0.47741, -0.52880,  0.22856,  0.35016,  0.12751,  0.49625,  0.63241,  0.22301,  0.57584, -0.01069, -0.46763], loss: 2.322e-02\n","iter 15: y_pred = [-0.49759,  0.17964,  0.40624,  0.12788,  0.35280,  0.64780,  0.19862,  0.50057,  0.12501, -0.48084, -0.51771,  0.23380,  0.35020,  0.12809,  0.49359,  0.65019,  0.22212,  0.57723,  0.00790, -0.47156], loss: 2.068e-02\n","iter 16: y_pred = [-0.51964,  0.16262,  0.37717,  0.13315,  0.37388,  0.67009,  0.19848,  0.49726,  0.10716, -0.48618, -0.50968,  0.23559,  0.34745,  0.12925,  0.49104,  0.66327,  0.22235,  0.58011,  0.02485, -0.47352], loss: 1.860e-02\n","iter 17: y_pred = [-0.53479,  0.15145,  0.34828,  0.13136,  0.39051,  0.68980,  0.20567,  0.50116,  0.09119, -0.49282, -0.50643,  0.23306,  0.34242,  0.13097,  0.48826,  0.67169,  0.22337,  0.58421,  0.03974, -0.47378], loss: 1.689e-02\n","iter 18: y_pred = [-0.54350,  0.14711,  0.32297,  0.12347,  0.40174,  0.70497,  0.21649,  0.51226,  0.07961, -0.49939, -0.50775,  0.22618,  0.33528,  0.13215,  0.48499,  0.67644,  0.22523,  0.58920,  0.05223, -0.47265], loss: 1.547e-02\n","iter 19: y_pred = [-0.54643,  0.14867,  0.30373,  0.11117,  0.40738,  0.71420,  0.22714,  0.52875,  0.07452, -0.50427, -0.51180,  0.21604,  0.32607,  0.13138,  0.48098,  0.67882,  0.22790,  0.59488,  0.06227, -0.47049], loss: 1.429e-02\n","iter 20: y_pred = [-0.54464,  0.15426,  0.29170,  0.09699,  0.40800,  0.71692,  0.23433,  0.54775,  0.07669, -0.50643, -0.51596,  0.20495,  0.31540,  0.12779,  0.47588,  0.67983,  0.23091,  0.60116,  0.07024, -0.46775], loss: 1.332e-02\n","iter 21: y_pred = [-0.53956,  0.16182,  0.28648,  0.08388,  0.40475,  0.71356,  0.23620,  0.56613,  0.08486, -0.50593, -0.51824,  0.19578,  0.30466,  0.12161,  0.46937,  0.68000,  0.23345,  0.60780,  0.07674, -0.46494], loss: 1.250e-02\n","iter 22: y_pred = [-0.53283,  0.16973,  0.28656,  0.07423,  0.39919,  0.70560,  0.23292,  0.58147,  0.09593, -0.50374, -0.51799,  0.19068,  0.29541,  0.11403,  0.46140,  0.67967,  0.23478,  0.61435,  0.08224, -0.46265], loss: 1.177e-02\n","iter 23: y_pred = [-0.52592,  0.17702,  0.29001,  0.06912,  0.39281,  0.69518,  0.22627,  0.59267,  0.10644, -0.50114, -0.51578,  0.19013,  0.28875,  0.10665,  0.45228,  0.67914,  0.23455,  0.62032,  0.08696, -0.46132], loss: 1.106e-02\n","iter 24: y_pred = [-0.51985,  0.18328,  0.29501,  0.06833,  0.38675,  0.68441,  0.21832,  0.59977,  0.11417, -0.49905, -0.51275,  0.19308,  0.28510,  0.10078,  0.44253,  0.67870,  0.23286,  0.62534,  0.09093, -0.46113], loss: 1.035e-02\n","iter 25: y_pred = [-0.51513,  0.18848,  0.30012,  0.07089,  0.38172,  0.67494,  0.21050,  0.60341,  0.11856, -0.49784, -0.50987,  0.19788,  0.28425,  0.09708,  0.43279,  0.67860,  0.23011,  0.62923,  0.09418, -0.46200], loss: 9.637e-03\n","iter 26: y_pred = [-0.51188,  0.19270,  0.30440,  0.07560,  0.37809,  0.66772,  0.20353,  0.60434,  0.12009, -0.49750, -0.50768,  0.20312,  0.28561,  0.09553,  0.42365,  0.67894,  0.22679,  0.63192,  0.09676, -0.46368], loss: 8.925e-03\n","iter 27: y_pred = [-0.50995,  0.19603,  0.30739,  0.08136,  0.37595,  0.66314,  0.19767,  0.60323,  0.11954, -0.49785, -0.50629,  0.20791,  0.28845,  0.09572,  0.41562,  0.67975,  0.22326,  0.63344,  0.09879, -0.46584], loss: 8.242e-03\n","iter 28: y_pred = [-0.50910,  0.19853,  0.30901,  0.08735,  0.37522,  0.66107,  0.19300,  0.60066,  0.11762, -0.49868, -0.50559,  0.21178,  0.29209,  0.09709,  0.40906,  0.68093,  0.21978,  0.63387,  0.10039, -0.46822], loss: 7.606e-03\n","iter 29: y_pred = [-0.50905,  0.20029,  0.30942,  0.09299,  0.37570,  0.66117,  0.18959,  0.59714,  0.11486, -0.49981, -0.50539,  0.21456,  0.29597,  0.09911,  0.40414,  0.68235,  0.21651,  0.63331,  0.10167, -0.47058], loss: 7.025e-03\n","iter 30: y_pred = [-0.50951,  0.20140,  0.30891,  0.09788,  0.37712,  0.66296,  0.18748,  0.59316,  0.11165, -0.50112, -0.50551,  0.21624,  0.29967,  0.10134,  0.40082,  0.68390,  0.21356,  0.63192,  0.10267, -0.47280], loss: 6.505e-03\n","iter 31: y_pred = [-0.51019,  0.20203,  0.30782,  0.10178,  0.37922,  0.66595,  0.18663,  0.58914,  0.10830, -0.50253, -0.50584,  0.21689,  0.30291,  0.10346,  0.39892,  0.68547,  0.21102,  0.62988,  0.10340, -0.47478], loss: 6.042e-03\n","iter 32: y_pred = [-0.51084,  0.20233,  0.30646,  0.10459,  0.38168,  0.66967,  0.18691,  0.58548,  0.10504, -0.50396, -0.50632,  0.21664,  0.30553,  0.10525,  0.39818,  0.68699,  0.20893,  0.62739,  0.10388, -0.47647], loss: 5.633e-03\n","iter 33: y_pred = [-0.51129,  0.20245,  0.30509,  0.10632,  0.38426,  0.67371,  0.18811,  0.58248,  0.10207, -0.50538, -0.50689,  0.21562,  0.30742,  0.10659,  0.39829,  0.68842,  0.20733,  0.62466,  0.10414, -0.47787], loss: 5.271e-03\n","iter 34: y_pred = [-0.51141,  0.20252,  0.30390,  0.10708,  0.38673,  0.67772,  0.18995,  0.58035,  0.09952, -0.50671, -0.50752,  0.21400,  0.30856,  0.10742,  0.39893,  0.68972,  0.20620,  0.62189,  0.10419, -0.47898], loss: 4.950e-03\n","iter 35: y_pred = [-0.51114,  0.20261,  0.30299,  0.10705,  0.38894,  0.68144,  0.19212,  0.57917,  0.09751, -0.50791, -0.50816,  0.21195,  0.30899,  0.10774,  0.39983,  0.69086,  0.20547,  0.61926,  0.10410, -0.47984], loss: 4.665e-03\n","iter 36: y_pred = [-0.51048,  0.20277,  0.30243,  0.10646,  0.39081,  0.68469,  0.19432,  0.57893,  0.09608, -0.50894, -0.50875,  0.20965,  0.30877,  0.10757,  0.40076,  0.69183,  0.20507,  0.61690,  0.10392, -0.48049], loss: 4.410e-03\n","iter 37: y_pred = [-0.50948,  0.20302,  0.30220,  0.10552,  0.39230,  0.68737,  0.19634,  0.57949,  0.09524, -0.50976, -0.50922,  0.20729,  0.30802,  0.10698,  0.40156,  0.69263,  0.20490,  0.61488,  0.10369, -0.48100], loss: 4.181e-03\n","iter 38: y_pred = [-0.50821,  0.20333,  0.30228,  0.10443,  0.39346,  0.68948,  0.19802,  0.58066,  0.09493, -0.51035, -0.50951,  0.20501,  0.30687,  0.10605,  0.40210,  0.69326,  0.20486,  0.61323,  0.10347, -0.48143], loss: 3.971e-03\n","iter 39: y_pred = [-0.50677,  0.20370,  0.30261,  0.10335,  0.39435,  0.69105,  0.19927,  0.58225,  0.09506, -0.51072, -0.50960,  0.20297,  0.30549,  0.10490,  0.40234,  0.69373,  0.20487,  0.61193,  0.10328, -0.48182], loss: 3.778e-03\n","iter 40: y_pred = [-0.50525,  0.20408,  0.30312,  0.10240,  0.39502,  0.69219,  0.20010,  0.58403,  0.09551, -0.51090, -0.50948,  0.20124,  0.30399,  0.10362,  0.40226,  0.69405,  0.20483,  0.61093,  0.10315, -0.48223], loss: 3.598e-03\n","iter 41: y_pred = [-0.50374,  0.20446,  0.30375,  0.10164,  0.39557,  0.69301,  0.20055,  0.58583,  0.09614, -0.51092, -0.50917,  0.19986,  0.30252,  0.10231,  0.40188,  0.69425,  0.20470,  0.61016,  0.10308, -0.48268], loss: 3.430e-03\n","iter 42: y_pred = [-0.50232,  0.20483,  0.30445,  0.10110,  0.39605,  0.69362,  0.20071,  0.58753,  0.09683, -0.51082, -0.50870,  0.19883,  0.30117,  0.10107,  0.40127,  0.69435,  0.20445,  0.60955,  0.10306, -0.48321], loss: 3.270e-03\n","iter 43: y_pred = [-0.50103,  0.20517,  0.30516,  0.10079,  0.39650,  0.69415,  0.20067,  0.58902,  0.09749, -0.51065, -0.50813,  0.19811,  0.30001,  0.09995,  0.40049,  0.69437,  0.20408,  0.60901,  0.10309, -0.48382], loss: 3.118e-03\n","iter 44: y_pred = [-0.49991,  0.20547,  0.30583,  0.10066,  0.39698,  0.69467,  0.20051,  0.59029,  0.09807, -0.51044, -0.50752,  0.19764,  0.29906,  0.09900,  0.39962,  0.69432,  0.20358,  0.60850,  0.10314, -0.48451], loss: 2.974e-03\n","iter 45: y_pred = [-0.49896,  0.20573,  0.30645,  0.10069,  0.39749,  0.69526,  0.20031,  0.59130,  0.09852, -0.51020, -0.50689,  0.19735,  0.29834,  0.09822,  0.39874,  0.69424,  0.20298,  0.60797,  0.10318, -0.48527], loss: 2.837e-03\n","iter 46: y_pred = [-0.49818,  0.20594,  0.30697,  0.10083,  0.39805,  0.69594,  0.20014,  0.59208,  0.09883, -0.50996, -0.50630,  0.19718,  0.29782,  0.09763,  0.39790,  0.69414,  0.20232,  0.60737,  0.10320, -0.48609], loss: 2.706e-03\n","iter 47: y_pred = [-0.49756,  0.20610,  0.30740,  0.10104,  0.39866,  0.69675,  0.20004,  0.59268,  0.09902, -0.50973, -0.50575,  0.19708,  0.29748,  0.09720,  0.39716,  0.69402,  0.20163,  0.60670,  0.10319, -0.48695], loss: 2.583e-03\n","iter 48: y_pred = [-0.49706,  0.20621,  0.30773,  0.10126,  0.39931,  0.69767,  0.20004,  0.59312,  0.09910, -0.50950, -0.50527,  0.19699,  0.29728,  0.09690,  0.39655,  0.69390,  0.20093,  0.60595,  0.10312, -0.48784], loss: 2.467e-03\n","iter 49: y_pred = [-0.49668,  0.20627,  0.30797,  0.10146,  0.39999,  0.69869,  0.20014,  0.59345,  0.09911, -0.50927, -0.50484,  0.19688,  0.29718,  0.09670,  0.39607,  0.69378,  0.20026,  0.60514,  0.10301, -0.48874], loss: 2.359e-03\n","iter 50: y_pred = [-0.49639,  0.20628,  0.30812,  0.10162,  0.40068,  0.69978,  0.20035,  0.59374,  0.09907, -0.50903, -0.50446,  0.19675,  0.29713,  0.09658,  0.39574,  0.69368,  0.19964,  0.60428,  0.10284, -0.48964], loss: 2.257e-03\n","iter 51: y_pred = [-0.49616,  0.20624,  0.30821,  0.10171,  0.40136,  0.70092,  0.20064,  0.59400,  0.09902, -0.50878, -0.50413,  0.19659,  0.29711,  0.09650,  0.39554,  0.69358,  0.19907,  0.60339,  0.10262, -0.49052], loss: 2.162e-03\n","iter 52: y_pred = [-0.49597,  0.20616,  0.30823,  0.10174,  0.40202,  0.70206,  0.20101,  0.59428,  0.09897, -0.50851, -0.50383,  0.19640,  0.29709,  0.09645,  0.39546,  0.69349,  0.19858,  0.60249,  0.10236, -0.49138], loss: 2.073e-03\n","iter 53: y_pred = [-0.49582,  0.20603,  0.30820,  0.10169,  0.40264,  0.70318,  0.20142,  0.59460,  0.09895, -0.50821, -0.50355,  0.19618,  0.29705,  0.09641,  0.39547,  0.69341,  0.19816,  0.60161,  0.10206, -0.49222], loss: 1.990e-03\n","iter 54: y_pred = [-0.49570,  0.20588,  0.30814,  0.10157,  0.40321,  0.70424,  0.20185,  0.59496,  0.09897, -0.50787, -0.50328,  0.19597,  0.29699,  0.09637,  0.39556,  0.69335,  0.19781,  0.60077,  0.10174, -0.49302], loss: 1.912e-03\n","iter 55: y_pred = [-0.49559,  0.20569,  0.30806,  0.10140,  0.40372,  0.70523,  0.20228,  0.59537,  0.09903, -0.50750, -0.50302,  0.19576,  0.29691,  0.09632,  0.39569,  0.69329,  0.19753,  0.59998,  0.10141, -0.49380], loss: 1.840e-03\n","iter 56: y_pred = [-0.49551,  0.20547,  0.30795,  0.10119,  0.40417,  0.70613,  0.20270,  0.59583,  0.09915, -0.50710, -0.50274,  0.19557,  0.29680,  0.09626,  0.39586,  0.69325,  0.19730,  0.59925,  0.10106, -0.49455], loss: 1.773e-03\n","iter 57: y_pred = [-0.49545,  0.20523,  0.30783,  0.10095,  0.40455,  0.70693,  0.20307,  0.59633,  0.09931, -0.50666, -0.50246,  0.19542,  0.29668,  0.09620,  0.39605,  0.69321,  0.19713,  0.59859,  0.10072, -0.49527], loss: 1.710e-03\n","iter 58: y_pred = [-0.49541,  0.20497,  0.30769,  0.10069,  0.40487,  0.70763,  0.20340,  0.59685,  0.09950, -0.50619, -0.50217,  0.19531,  0.29655,  0.09614,  0.39624,  0.69318,  0.19700,  0.59801,  0.10039, -0.49596], loss: 1.651e-03\n","iter 59: y_pred = [-0.49541,  0.20469,  0.30754,  0.10044,  0.40512,  0.70822,  0.20368,  0.59738,  0.09972, -0.50569, -0.50187,  0.19526,  0.29643,  0.09610,  0.39643,  0.69317,  0.19690,  0.59749,  0.10007, -0.49663], loss: 1.596e-03\n","iter 60: y_pred = [-0.49543,  0.20440,  0.30737,  0.10018,  0.40531,  0.70872,  0.20391,  0.59791,  0.09996, -0.50517, -0.50157,  0.19526,  0.29632,  0.09607,  0.39661,  0.69317,  0.19683,  0.59704,  0.09977, -0.49727], loss: 1.544e-03\n","iter 61: y_pred = [-0.49549,  0.20410,  0.30718,  0.09994,  0.40544,  0.70912,  0.20409,  0.59842,  0.10021, -0.50464, -0.50126,  0.19531,  0.29624,  0.09606,  0.39679,  0.69318,  0.19678,  0.59666,  0.09948, -0.49788], loss: 1.495e-03\n","iter 62: y_pred = [-0.49558,  0.20378,  0.30697,  0.09972,  0.40553,  0.70943,  0.20422,  0.59891,  0.10046, -0.50411, -0.50096,  0.19541,  0.29618,  0.09607,  0.39697,  0.69321,  0.19675,  0.59633,  0.09922, -0.49847], loss: 1.449e-03\n","iter 63: y_pred = [-0.49571,  0.20347,  0.30674,  0.09952,  0.40556,  0.70967,  0.20432,  0.59937,  0.10069, -0.50357, -0.50067,  0.19556,  0.29616,  0.09612,  0.39714,  0.69325,  0.19674,  0.59604,  0.09897, -0.49903], loss: 1.406e-03\n","iter 64: y_pred = [-0.49588,  0.20314,  0.30649,  0.09934,  0.40556,  0.70984,  0.20438,  0.59979,  0.10092, -0.50303, -0.50039,  0.19575,  0.29618,  0.09619,  0.39732,  0.69332,  0.19674,  0.59581,  0.09874, -0.49957], loss: 1.365e-03\n","iter 65: y_pred = [-0.49607,  0.20282,  0.30622,  0.09918,  0.40551,  0.70995,  0.20441,  0.60017,  0.10112, -0.50250, -0.50013,  0.19596,  0.29622,  0.09630,  0.39750,  0.69340,  0.19675,  0.59561,  0.09852, -0.50007], loss: 1.327e-03\n","iter 66: y_pred = [-0.49630,  0.20249,  0.30593,  0.09904,  0.40543,  0.70999,  0.20441,  0.60051,  0.10131, -0.50199, -0.49988,  0.19620,  0.29631,  0.09644,  0.39769,  0.69350,  0.19678,  0.59545,  0.09832, -0.50055], loss: 1.291e-03\n","iter 67: y_pred = [-0.49655,  0.20216,  0.30562,  0.09891,  0.40532,  0.70998,  0.20440,  0.60082,  0.10147, -0.50149, -0.49965,  0.19646,  0.29642,  0.09660,  0.39789,  0.69362,  0.19683,  0.59533,  0.09814, -0.50100], loss: 1.256e-03\n","iter 68: y_pred = [-0.49682,  0.20184,  0.30529,  0.09880,  0.40518,  0.70993,  0.20437,  0.60109,  0.10161, -0.50100, -0.49945,  0.19674,  0.29655,  0.09678,  0.39810,  0.69376,  0.19690,  0.59523,  0.09797, -0.50141], loss: 1.224e-03\n","iter 69: y_pred = [-0.49710,  0.20151,  0.30494,  0.09869,  0.40502,  0.70982,  0.20432,  0.60132,  0.10174, -0.50054, -0.49926,  0.19702,  0.29671,  0.09698,  0.39832,  0.69392,  0.19698,  0.59517,  0.09781, -0.50179], loss: 1.193e-03\n","iter 70: y_pred = [-0.49740,  0.20119,  0.30458,  0.09860,  0.40482,  0.70966,  0.20426,  0.60153,  0.10185, -0.50009, -0.49910,  0.19731,  0.29689,  0.09719,  0.39855,  0.69409,  0.19708,  0.59513,  0.09767, -0.50214], loss: 1.163e-03\n","iter 71: y_pred = [-0.49771,  0.20088,  0.30421,  0.09851,  0.40461,  0.70946,  0.20419,  0.60172,  0.10194, -0.49967, -0.49895,  0.19759,  0.29708,  0.09742,  0.39878,  0.69429,  0.19720,  0.59513,  0.09754, -0.50245], loss: 1.135e-03\n","iter 72: y_pred = [-0.49802,  0.20058,  0.30384,  0.09843,  0.40437,  0.70922,  0.20410,  0.60187,  0.10202, -0.49928, -0.49883,  0.19788,  0.29728,  0.09766,  0.39903,  0.69450,  0.19733,  0.59516,  0.09743, -0.50273], loss: 1.107e-03\n","iter 73: y_pred = [-0.49833,  0.20028,  0.30346,  0.09836,  0.40412,  0.70893,  0.20400,  0.60201,  0.10208, -0.49890, -0.49872,  0.19817,  0.29748,  0.09790,  0.39927,  0.69472,  0.19748,  0.59521,  0.09733, -0.50297], loss: 1.081e-03\n","iter 74: y_pred = [-0.49864,  0.20000,  0.30308,  0.09830,  0.40385,  0.70861,  0.20389,  0.60213,  0.10213, -0.49856, -0.49862,  0.19846,  0.29769,  0.09814,  0.39951,  0.69496,  0.19764,  0.59530,  0.09725, -0.50318], loss: 1.056e-03\n","iter 75: y_pred = [-0.49895,  0.19973,  0.30270,  0.09824,  0.40356,  0.70824,  0.20376,  0.60223,  0.10217, -0.49823, -0.49855,  0.19874,  0.29790,  0.09838,  0.39975,  0.69521,  0.19781,  0.59541,  0.09719, -0.50335], loss: 1.031e-03\n","iter 76: y_pred = [-0.49925,  0.19947,  0.30233,  0.09819,  0.40326,  0.70784,  0.20362,  0.60231,  0.10220, -0.49794, -0.49848,  0.19901,  0.29811,  0.09862,  0.39998,  0.69547,  0.19799,  0.59555,  0.09714, -0.50349], loss: 1.008e-03\n","iter 77: y_pred = [-0.49955,  0.19923,  0.30196,  0.09816,  0.40294,  0.70741,  0.20347,  0.60237,  0.10222, -0.49767, -0.49843,  0.19928,  0.29833,  0.09886,  0.40021,  0.69573,  0.19818,  0.59571,  0.09711, -0.50360], loss: 9.844e-04\n","iter 78: y_pred = [-0.49984,  0.19900,  0.30160,  0.09813,  0.40262,  0.70695,  0.20330,  0.60242,  0.10223, -0.49742, -0.49840,  0.19955,  0.29854,  0.09909,  0.40043,  0.69600,  0.19837,  0.59589,  0.09709, -0.50368], loss: 9.619e-04\n","iter 79: y_pred = [-0.50012,  0.19879,  0.30125,  0.09811,  0.40229,  0.70646,  0.20313,  0.60245,  0.10223, -0.49720, -0.49837,  0.19980,  0.29875,  0.09932,  0.40063,  0.69628,  0.19857,  0.59610,  0.09710, -0.50373], loss: 9.399e-04\n","iter 80: y_pred = [-0.50039,  0.19859,  0.30092,  0.09810,  0.40196,  0.70596,  0.20294,  0.60246,  0.10222, -0.49701, -0.49836,  0.20005,  0.29895,  0.09955,  0.40082,  0.69656,  0.19877,  0.59632,  0.09712, -0.50375], loss: 9.185e-04\n","iter 81: y_pred = [-0.50064,  0.19841,  0.30059,  0.09810,  0.40163,  0.70543,  0.20275,  0.60246,  0.10220, -0.49685, -0.49836,  0.20029,  0.29915,  0.09976,  0.40100,  0.69685,  0.19897,  0.59656,  0.09715, -0.50374], loss: 8.976e-04\n","iter 82: y_pred = [-0.50088,  0.19826,  0.30028,  0.09812,  0.40130,  0.70490,  0.20255,  0.60244,  0.10216, -0.49672, -0.49837,  0.20053,  0.29935,  0.09998,  0.40117,  0.69713,  0.19916,  0.59681,  0.09720, -0.50370], loss: 8.772e-04\n","iter 83: y_pred = [-0.50111,  0.19811,  0.29998,  0.09814,  0.40098,  0.70435,  0.20234,  0.60241,  0.10212, -0.49661, -0.49838,  0.20074,  0.29955,  0.10018,  0.40132,  0.69741,  0.19936,  0.59707,  0.09726, -0.50364], loss: 8.573e-04\n","iter 84: y_pred = [-0.50133,  0.19799,  0.29970,  0.09817,  0.40066,  0.70381,  0.20213,  0.60236,  0.10207, -0.49652, -0.49841,  0.20095,  0.29974,  0.10037,  0.40146,  0.69769,  0.19955,  0.59734,  0.09733, -0.50356], loss: 8.378e-04\n","iter 85: y_pred = [-0.50153,  0.19789,  0.29943,  0.09821,  0.40034,  0.70326,  0.20192,  0.60230,  0.10201, -0.49646, -0.49845,  0.20115,  0.29992,  0.10056,  0.40159,  0.69797,  0.19973,  0.59762,  0.09742, -0.50346], loss: 8.188e-04\n","iter 86: y_pred = [-0.50171,  0.19780,  0.29918,  0.09826,  0.40004,  0.70271,  0.20170,  0.60223,  0.10194, -0.49643, -0.49850,  0.20133,  0.30010,  0.10073,  0.40170,  0.69824,  0.19991,  0.59790,  0.09752, -0.50334], loss: 8.003e-04\n","iter 87: y_pred = [-0.50188,  0.19773,  0.29895,  0.09832,  0.39975,  0.70217,  0.20149,  0.60214,  0.10187, -0.49642, -0.49855,  0.20150,  0.30027,  0.10090,  0.40180,  0.69851,  0.20008,  0.59818,  0.09762, -0.50320], loss: 7.822e-04\n","iter 88: y_pred = [-0.50203,  0.19768,  0.29874,  0.09838,  0.39947,  0.70164,  0.20128,  0.60204,  0.10179, -0.49643, -0.49862,  0.20165,  0.30043,  0.10105,  0.40188,  0.69877,  0.20025,  0.59847,  0.09774, -0.50305], loss: 7.646e-04\n","iter 89: y_pred = [-0.50217,  0.19764,  0.29854,  0.09845,  0.39920,  0.70112,  0.20107,  0.60194,  0.10170, -0.49646, -0.49869,  0.20178,  0.30058,  0.10120,  0.40195,  0.69902,  0.20041,  0.59875,  0.09786, -0.50288], loss: 7.474e-04\n","iter 90: y_pred = [-0.50228,  0.19762,  0.29836,  0.09853,  0.39895,  0.70062,  0.20087,  0.60182,  0.10160, -0.49652, -0.49876,  0.20191,  0.30073,  0.10133,  0.40201,  0.69927,  0.20055,  0.59902,  0.09799, -0.50270], loss: 7.307e-04\n","iter 91: y_pred = [-0.50238,  0.19762,  0.29820,  0.09860,  0.39872,  0.70014,  0.20067,  0.60170,  0.10150, -0.49659, -0.49884,  0.20201,  0.30086,  0.10144,  0.40205,  0.69951,  0.20069,  0.59929,  0.09812, -0.50251], loss: 7.145e-04\n","iter 92: y_pred = [-0.50247,  0.19763,  0.29806,  0.09869,  0.39850,  0.69967,  0.20047,  0.60157,  0.10140, -0.49668, -0.49892,  0.20210,  0.30099,  0.10155,  0.40209,  0.69973,  0.20082,  0.59956,  0.09826, -0.50231], loss: 6.987e-04\n","iter 93: y_pred = [-0.50253,  0.19765,  0.29794,  0.09877,  0.39830,  0.69923,  0.20029,  0.60144,  0.10130, -0.49678, -0.49901,  0.20218,  0.30110,  0.10164,  0.40211,  0.69995,  0.20094,  0.59982,  0.09840, -0.50210], loss: 6.835e-04\n","iter 94: y_pred = [-0.50258,  0.19769,  0.29784,  0.09886,  0.39811,  0.69881,  0.20011,  0.60130,  0.10119, -0.49690, -0.49910,  0.20224,  0.30120,  0.10172,  0.40211,  0.70015,  0.20105,  0.60007,  0.09854, -0.50188], loss: 6.687e-04\n","iter 95: y_pred = [-0.50262,  0.19773,  0.29775,  0.09895,  0.39795,  0.69841,  0.19994,  0.60117,  0.10108, -0.49703, -0.49919,  0.20228,  0.30129,  0.10179,  0.40211,  0.70035,  0.20115,  0.60031,  0.09869, -0.50167], loss: 6.543e-04\n","iter 96: y_pred = [-0.50264,  0.19779,  0.29768,  0.09905,  0.39780,  0.69804,  0.19977,  0.60102,  0.10098, -0.49718, -0.49928,  0.20231,  0.30137,  0.10185,  0.40210,  0.70053,  0.20124,  0.60053,  0.09883, -0.50145], loss: 6.405e-04\n","iter 97: y_pred = [-0.50264,  0.19786,  0.29763,  0.09914,  0.39767,  0.69770,  0.19962,  0.60088,  0.10087, -0.49733, -0.49938,  0.20233,  0.30144,  0.10189,  0.40207,  0.70069,  0.20132,  0.60075,  0.09898, -0.50123], loss: 6.270e-04\n","iter 98: y_pred = [-0.50263,  0.19794,  0.29760,  0.09923,  0.39755,  0.69738,  0.19948,  0.60074,  0.10076, -0.49750, -0.49947,  0.20233,  0.30150,  0.10192,  0.40204,  0.70085,  0.20138,  0.60096,  0.09912, -0.50100], loss: 6.141e-04\n","iter 99: y_pred = [-0.50260,  0.19803,  0.29758,  0.09932,  0.39746,  0.69709,  0.19934,  0.60060,  0.10065, -0.49767, -0.49956,  0.20232,  0.30154,  0.10194,  0.40199,  0.70099,  0.20144,  0.60115,  0.09926, -0.50078], loss: 6.015e-04\n","iter  0: y_pred = [ 0.04135, -0.05685, -0.03941,  0.08084,  0.11429,  0.13576,  0.26216,  0.46805,  0.51899,  0.41713,  0.14586,  0.02868, -0.01903, -0.01157,  0.01944,  0.02866,  0.05470,  0.10151,  0.11715,  0.21227], loss: 9.152e-01\n","iter  1: y_pred = [ 0.04473,  0.07616,  0.12456,  0.15604,  0.15280,  0.12920,  0.15916,  0.25805,  0.27154,  0.17941,  0.10984,  0.09118,  0.07052,  0.07686,  0.12363,  0.10890,  0.11493,  0.16154,  0.15236,  0.21202], loss: 7.810e-01\n","iter  2: y_pred = [ 0.05001,  0.09609,  0.15210,  0.17981,  0.17048,  0.15188,  0.17916,  0.28100,  0.28599,  0.15805,  0.09003,  0.09066,  0.07531,  0.08177,  0.14736,  0.13893,  0.13992,  0.20090,  0.17139,  0.19631], loss: 6.798e-01\n","iter  3: y_pred = [ 0.04091,  0.09294,  0.15532,  0.18465,  0.16856,  0.16653,  0.19431,  0.31121,  0.30923,  0.13850,  0.05510,  0.06793,  0.06178,  0.07538,  0.17126,  0.17855,  0.17444,  0.25876,  0.19864,  0.17823], loss: 6.039e-01\n","iter  4: y_pred = [ 0.01237,  0.06490,  0.13887,  0.17631,  0.15586,  0.18485,  0.22034,  0.36373,  0.35017,  0.11338, -0.00571,  0.02084,  0.03965,  0.07429,  0.21909,  0.24796,  0.23074,  0.34189,  0.22552,  0.13359], loss: 5.113e-01\n","iter  5: y_pred = [-0.05576,  0.00167,  0.11386,  0.17261,  0.15386,  0.23362,  0.27483,  0.44532,  0.40038,  0.05819, -0.11131, -0.04256,  0.03672,  0.11331,  0.31736,  0.35065,  0.29337,  0.42228,  0.21267,  0.02771], loss: 3.649e-01\n","iter  6: y_pred = [-0.15426, -0.04553,  0.14528,  0.20138,  0.17261,  0.31214,  0.31953,  0.50382,  0.41222, -0.06209, -0.26051, -0.06414,  0.08891,  0.19662,  0.42833,  0.42965,  0.31648,  0.46618,  0.13756, -0.10899], loss: 2.230e-01\n","iter  7: y_pred = [-0.22805, -0.01354,  0.22092,  0.17824,  0.18576,  0.40050,  0.32457,  0.52118,  0.37895, -0.21846, -0.39716,  0.01019,  0.15171,  0.23004,  0.47253,  0.44495,  0.31460,  0.50202,  0.04124, -0.21602], loss: 1.391e-01\n","iter  8: y_pred = [-0.26311,  0.06060,  0.27389,  0.07868,  0.24327,  0.50791,  0.31358,  0.51713,  0.32289, -0.34389, -0.48327,  0.10342,  0.19790,  0.19814,  0.48363,  0.46362,  0.31082,  0.53320, -0.03748, -0.29826], loss: 9.021e-02\n","iter  9: y_pred = [-0.27709,  0.12393,  0.31591,  0.00372,  0.29531,  0.57666,  0.31270,  0.51543,  0.26634, -0.41445, -0.52514,  0.16047,  0.24956,  0.15343,  0.49618,  0.50410,  0.28627,  0.54978, -0.07490, -0.36283], loss: 6.125e-02\n","iter 10: y_pred = [-0.29937,  0.17138,  0.36407, -0.01306,  0.30745,  0.59887,  0.31032,  0.51683,  0.21920, -0.44952, -0.54275,  0.18999,  0.29458,  0.12697,  0.50446,  0.54127,  0.25958,  0.56274, -0.07920, -0.40755], loss: 4.521e-02\n","iter 11: y_pred = [-0.34001,  0.20564,  0.41139,  0.01237,  0.30133,  0.59884,  0.29343,  0.51991,  0.18791, -0.46578, -0.54854,  0.20465,  0.32391,  0.12083,  0.50553,  0.56759,  0.24217,  0.57143, -0.06768, -0.43544], loss: 3.612e-02\n","iter 12: y_pred = [-0.38750,  0.21941,  0.44105,  0.05635,  0.29710,  0.59723,  0.26399,  0.52138,  0.16982, -0.47261, -0.54702,  0.21362,  0.33938,  0.12352,  0.50280,  0.58947,  0.23193,  0.57498, -0.05004, -0.45168], loss: 3.042e-02\n","iter 13: y_pred = [-0.43145,  0.21473,  0.44561,  0.09246,  0.30761,  0.60655,  0.23245,  0.51732,  0.15683, -0.47533, -0.53971,  0.22138,  0.34689,  0.12641,  0.49934,  0.61136,  0.22595,  0.57559, -0.03037, -0.46138], loss: 2.637e-02\n","iter 14: y_pred = [-0.46827,  0.19901,  0.43112,  0.11491,  0.32919,  0.62540,  0.20941,  0.50878,  0.14224, -0.47743, -0.52882,  0.22854,  0.35016,  0.12753,  0.49626,  0.63241,  0.22302,  0.57585, -0.01070, -0.46762], loss: 2.322e-02\n","iter 15: y_pred = [-0.49757,  0.17965,  0.40623,  0.12784,  0.35278,  0.64780,  0.19867,  0.50060,  0.12500, -0.48086, -0.51774,  0.23377,  0.35019,  0.12809,  0.49360,  0.65017,  0.22213,  0.57724,  0.00789, -0.47154], loss: 2.069e-02\n","iter 16: y_pred = [-0.51961,  0.16264,  0.37717,  0.13311,  0.37386,  0.67008,  0.19852,  0.49731,  0.10717, -0.48619, -0.50972,  0.23555,  0.34743,  0.12925,  0.49105,  0.66326,  0.22236,  0.58012,  0.02484, -0.47350], loss: 1.861e-02\n","iter 17: y_pred = [-0.53476,  0.15147,  0.34829,  0.13133,  0.39048,  0.68978,  0.20569,  0.50121,  0.09121, -0.49283, -0.50646,  0.23302,  0.34240,  0.13096,  0.48827,  0.67168,  0.22338,  0.58422,  0.03973, -0.47377], loss: 1.689e-02\n","iter 18: y_pred = [-0.54346,  0.14712,  0.32300,  0.12345,  0.40171,  0.70493,  0.21649,  0.51231,  0.07965, -0.49938, -0.50777,  0.22615,  0.33525,  0.13213,  0.48500,  0.67643,  0.22525,  0.58921,  0.05221, -0.47264], loss: 1.547e-02\n","iter 19: y_pred = [-0.54640,  0.14868,  0.30376,  0.11116,  0.40736,  0.71416,  0.22712,  0.52878,  0.07456, -0.50426, -0.51180,  0.21603,  0.32604,  0.13135,  0.48098,  0.67882,  0.22791,  0.59490,  0.06226, -0.47049], loss: 1.430e-02\n","iter 20: y_pred = [-0.54462,  0.15426,  0.29173,  0.09699,  0.40797,  0.71688,  0.23430,  0.54776,  0.07674, -0.50642, -0.51595,  0.20496,  0.31539,  0.12776,  0.47587,  0.67982,  0.23091,  0.60118,  0.07024, -0.46775], loss: 1.332e-02\n","iter 21: y_pred = [-0.53955,  0.16182,  0.28650,  0.08390,  0.40474,  0.71352,  0.23616,  0.56613,  0.08489, -0.50592, -0.51822,  0.19580,  0.30466,  0.12159,  0.46935,  0.67999,  0.23344,  0.60782,  0.07674, -0.46495], loss: 1.250e-02\n","iter 22: y_pred = [-0.53282,  0.16973,  0.28658,  0.07425,  0.39919,  0.70558,  0.23289,  0.58145,  0.09594, -0.50374, -0.51797,  0.19071,  0.29542,  0.11403,  0.46138,  0.67966,  0.23477,  0.61436,  0.08225, -0.46266], loss: 1.177e-02\n","iter 23: y_pred = [-0.52592,  0.17701,  0.29002,  0.06914,  0.39281,  0.69517,  0.22625,  0.59264,  0.10643, -0.50115, -0.51577,  0.19016,  0.28877,  0.10665,  0.45226,  0.67913,  0.23453,  0.62032,  0.08696, -0.46132], loss: 1.106e-02\n","iter 24: y_pred = [-0.51986,  0.18327,  0.29501,  0.06835,  0.38676,  0.68442,  0.21831,  0.59974,  0.11415, -0.49905, -0.51275,  0.19310,  0.28512,  0.10079,  0.44252,  0.67870,  0.23284,  0.62534,  0.09094, -0.46114], loss: 1.036e-02\n","iter 25: y_pred = [-0.51514,  0.18848,  0.30012,  0.07091,  0.38173,  0.67494,  0.21050,  0.60338,  0.11854, -0.49785, -0.50987,  0.19789,  0.28428,  0.09710,  0.43279,  0.67859,  0.23010,  0.62922,  0.09418, -0.46201], loss: 9.637e-03\n","iter 26: y_pred = [-0.51188,  0.19270,  0.30439,  0.07561,  0.37810,  0.66774,  0.20354,  0.60432,  0.12007, -0.49751, -0.50768,  0.20313,  0.28564,  0.09555,  0.42365,  0.67894,  0.22678,  0.63191,  0.09675, -0.46369], loss: 8.926e-03\n","iter 27: y_pred = [-0.50995,  0.19603,  0.30739,  0.08136,  0.37596,  0.66315,  0.19768,  0.60321,  0.11952, -0.49787, -0.50630,  0.20791,  0.28847,  0.09574,  0.41563,  0.67975,  0.22325,  0.63343,  0.09878, -0.46585], loss: 8.243e-03\n","iter 28: y_pred = [-0.50911,  0.19853,  0.30901,  0.08735,  0.37522,  0.66109,  0.19301,  0.60064,  0.11761, -0.49869, -0.50560,  0.21177,  0.29210,  0.09710,  0.40908,  0.68093,  0.21978,  0.63385,  0.10039, -0.46822], loss: 7.606e-03\n","iter 29: y_pred = [-0.50906,  0.20028,  0.30942,  0.09299,  0.37570,  0.66119,  0.18961,  0.59713,  0.11485, -0.49982, -0.50539,  0.21455,  0.29597,  0.09912,  0.40415,  0.68235,  0.21651,  0.63330,  0.10167, -0.47058], loss: 7.026e-03\n","iter 30: y_pred = [-0.50951,  0.20140,  0.30891,  0.09788,  0.37713,  0.66298,  0.18750,  0.59315,  0.11165, -0.50113, -0.50551,  0.21623,  0.29967,  0.10134,  0.40083,  0.68390,  0.21357,  0.63191,  0.10266, -0.47280], loss: 6.506e-03\n","iter 31: y_pred = [-0.51018,  0.20203,  0.30782,  0.10178,  0.37922,  0.66596,  0.18665,  0.58914,  0.10830, -0.50253, -0.50584,  0.21688,  0.30291,  0.10346,  0.39894,  0.68547,  0.21102,  0.62987,  0.10340, -0.47478], loss: 6.043e-03\n","iter 32: y_pred = [-0.51084,  0.20232,  0.30646,  0.10458,  0.38168,  0.66967,  0.18693,  0.58548,  0.10504, -0.50397, -0.50632,  0.21663,  0.30552,  0.10525,  0.39820,  0.68700,  0.20894,  0.62738,  0.10388, -0.47647], loss: 5.633e-03\n","iter 33: y_pred = [-0.51129,  0.20245,  0.30509,  0.10631,  0.38426,  0.67371,  0.18812,  0.58249,  0.10207, -0.50538, -0.50689,  0.21561,  0.30741,  0.10659,  0.39830,  0.68843,  0.20734,  0.62465,  0.10413, -0.47786], loss: 5.271e-03\n","iter 34: y_pred = [-0.51141,  0.20251,  0.30390,  0.10707,  0.38673,  0.67772,  0.18995,  0.58036,  0.09952, -0.50671, -0.50752,  0.21399,  0.30856,  0.10742,  0.39894,  0.68972,  0.20620,  0.62189,  0.10419, -0.47897], loss: 4.951e-03\n","iter 35: y_pred = [-0.51114,  0.20261,  0.30299,  0.10704,  0.38894,  0.68144,  0.19212,  0.57918,  0.09751, -0.50791, -0.50816,  0.21195,  0.30898,  0.10773,  0.39983,  0.69086,  0.20547,  0.61927,  0.10410, -0.47983], loss: 4.666e-03\n","iter 36: y_pred = [-0.51048,  0.20277,  0.30243,  0.10645,  0.39080,  0.68469,  0.19432,  0.57894,  0.09609, -0.50894, -0.50874,  0.20965,  0.30876,  0.10756,  0.40076,  0.69183,  0.20507,  0.61690,  0.10392, -0.48049], loss: 4.411e-03\n","iter 37: y_pred = [-0.50948,  0.20302,  0.30221,  0.10551,  0.39230,  0.68737,  0.19634,  0.57949,  0.09525, -0.50976, -0.50921,  0.20729,  0.30801,  0.10697,  0.40156,  0.69263,  0.20491,  0.61488,  0.10369, -0.48100], loss: 4.181e-03\n","iter 38: y_pred = [-0.50821,  0.20333,  0.30228,  0.10443,  0.39346,  0.68947,  0.19801,  0.58067,  0.09494, -0.51035, -0.50951,  0.20502,  0.30687,  0.10605,  0.40210,  0.69326,  0.20487,  0.61323,  0.10347, -0.48143], loss: 3.972e-03\n","iter 39: y_pred = [-0.50676,  0.20370,  0.30261,  0.10335,  0.39434,  0.69104,  0.19926,  0.58225,  0.09507, -0.51072, -0.50960,  0.20297,  0.30548,  0.10489,  0.40233,  0.69373,  0.20487,  0.61193,  0.10328, -0.48182], loss: 3.779e-03\n","iter 40: y_pred = [-0.50525,  0.20408,  0.30312,  0.10240,  0.39502,  0.69218,  0.20009,  0.58403,  0.09551, -0.51090, -0.50948,  0.20124,  0.30399,  0.10362,  0.40225,  0.69405,  0.20483,  0.61093,  0.10315, -0.48223], loss: 3.599e-03\n","iter 41: y_pred = [-0.50374,  0.20446,  0.30375,  0.10164,  0.39557,  0.69300,  0.20055,  0.58583,  0.09614, -0.51092, -0.50916,  0.19986,  0.30252,  0.10231,  0.40187,  0.69425,  0.20470,  0.61016,  0.10308, -0.48268], loss: 3.430e-03\n","iter 42: y_pred = [-0.50232,  0.20483,  0.30445,  0.10111,  0.39604,  0.69362,  0.20071,  0.58752,  0.09683, -0.51082, -0.50870,  0.19883,  0.30117,  0.10107,  0.40126,  0.69435,  0.20445,  0.60955,  0.10306, -0.48321], loss: 3.270e-03\n","iter 43: y_pred = [-0.50103,  0.20517,  0.30516,  0.10079,  0.39650,  0.69415,  0.20067,  0.58902,  0.09749, -0.51065, -0.50813,  0.19811,  0.30001,  0.09995,  0.40049,  0.69437,  0.20407,  0.60902,  0.10309, -0.48382], loss: 3.119e-03\n","iter 44: y_pred = [-0.49991,  0.20547,  0.30583,  0.10066,  0.39698,  0.69467,  0.20051,  0.59028,  0.09807, -0.51044, -0.50752,  0.19764,  0.29906,  0.09900,  0.39962,  0.69432,  0.20358,  0.60850,  0.10314, -0.48451], loss: 2.974e-03\n","iter 45: y_pred = [-0.49896,  0.20573,  0.30645,  0.10070,  0.39749,  0.69526,  0.20031,  0.59130,  0.09852, -0.51020, -0.50689,  0.19736,  0.29834,  0.09823,  0.39874,  0.69424,  0.20298,  0.60796,  0.10318, -0.48527], loss: 2.837e-03\n","iter 46: y_pred = [-0.49818,  0.20594,  0.30697,  0.10084,  0.39805,  0.69594,  0.20014,  0.59208,  0.09883, -0.50997, -0.50630,  0.19719,  0.29783,  0.09763,  0.39790,  0.69414,  0.20232,  0.60737,  0.10320, -0.48609], loss: 2.707e-03\n","iter 47: y_pred = [-0.49756,  0.20610,  0.30740,  0.10104,  0.39866,  0.69675,  0.20004,  0.59267,  0.09902, -0.50973, -0.50575,  0.19708,  0.29749,  0.09720,  0.39716,  0.69402,  0.20163,  0.60670,  0.10319, -0.48696], loss: 2.584e-03\n","iter 48: y_pred = [-0.49707,  0.20621,  0.30773,  0.10126,  0.39931,  0.69767,  0.20004,  0.59311,  0.09910, -0.50950, -0.50527,  0.19699,  0.29728,  0.09690,  0.39655,  0.69390,  0.20093,  0.60595,  0.10312, -0.48784], loss: 2.468e-03\n","iter 49: y_pred = [-0.49668,  0.20627,  0.30797,  0.10146,  0.39999,  0.69869,  0.20014,  0.59345,  0.09911, -0.50927, -0.50484,  0.19688,  0.29718,  0.09670,  0.39607,  0.69378,  0.20026,  0.60514,  0.10301, -0.48874], loss: 2.359e-03\n","iter 50: y_pred = [-0.49639,  0.20628,  0.30812,  0.10162,  0.40068,  0.69979,  0.20035,  0.59374,  0.09907, -0.50903, -0.50446,  0.19675,  0.29713,  0.09658,  0.39574,  0.69368,  0.19964,  0.60428,  0.10284, -0.48964], loss: 2.257e-03\n","iter 51: y_pred = [-0.49616,  0.20624,  0.30820,  0.10171,  0.40136,  0.70092,  0.20064,  0.59400,  0.09902, -0.50878, -0.50413,  0.19659,  0.29711,  0.09650,  0.39554,  0.69358,  0.19907,  0.60339,  0.10262, -0.49052], loss: 2.162e-03\n","iter 52: y_pred = [-0.49597,  0.20616,  0.30823,  0.10174,  0.40202,  0.70206,  0.20101,  0.59428,  0.09897, -0.50851, -0.50383,  0.19640,  0.29709,  0.09645,  0.39546,  0.69349,  0.19858,  0.60249,  0.10236, -0.49138], loss: 2.073e-03\n","iter 53: y_pred = [-0.49582,  0.20603,  0.30820,  0.10169,  0.40264,  0.70318,  0.20142,  0.59460,  0.09895, -0.50821, -0.50355,  0.19618,  0.29705,  0.09641,  0.39547,  0.69341,  0.19816,  0.60161,  0.10206, -0.49222], loss: 1.990e-03\n","iter 54: y_pred = [-0.49570,  0.20587,  0.30814,  0.10157,  0.40321,  0.70424,  0.20185,  0.59496,  0.09897, -0.50787, -0.50328,  0.19596,  0.29699,  0.09637,  0.39556,  0.69335,  0.19781,  0.60077,  0.10174, -0.49302], loss: 1.913e-03\n","iter 55: y_pred = [-0.49559,  0.20568,  0.30806,  0.10140,  0.40372,  0.70523,  0.20228,  0.59537,  0.09903, -0.50750, -0.50301,  0.19576,  0.29691,  0.09632,  0.39569,  0.69329,  0.19753,  0.59998,  0.10141, -0.49380], loss: 1.841e-03\n","iter 56: y_pred = [-0.49551,  0.20547,  0.30795,  0.10119,  0.40417,  0.70613,  0.20269,  0.59583,  0.09915, -0.50710, -0.50274,  0.19557,  0.29680,  0.09626,  0.39586,  0.69325,  0.19731,  0.59925,  0.10106, -0.49455], loss: 1.773e-03\n","iter 57: y_pred = [-0.49545,  0.20523,  0.30783,  0.10095,  0.40455,  0.70693,  0.20307,  0.59633,  0.09931, -0.50666, -0.50246,  0.19542,  0.29668,  0.09620,  0.39605,  0.69321,  0.19713,  0.59859,  0.10072, -0.49527], loss: 1.710e-03\n","iter 58: y_pred = [-0.49541,  0.20497,  0.30769,  0.10069,  0.40487,  0.70763,  0.20340,  0.59685,  0.09950, -0.50619, -0.50217,  0.19531,  0.29655,  0.09614,  0.39624,  0.69318,  0.19700,  0.59801,  0.10039, -0.49596], loss: 1.651e-03\n","iter 59: y_pred = [-0.49541,  0.20469,  0.30754,  0.10044,  0.40512,  0.70822,  0.20368,  0.59738,  0.09972, -0.50569, -0.50187,  0.19526,  0.29643,  0.09610,  0.39643,  0.69317,  0.19690,  0.59749,  0.10007, -0.49663], loss: 1.596e-03\n","iter 60: y_pred = [-0.49543,  0.20440,  0.30737,  0.10018,  0.40531,  0.70871,  0.20391,  0.59791,  0.09996, -0.50517, -0.50157,  0.19526,  0.29632,  0.09607,  0.39661,  0.69317,  0.19683,  0.59704,  0.09977, -0.49727], loss: 1.544e-03\n","iter 61: y_pred = [-0.49549,  0.20410,  0.30718,  0.09995,  0.40544,  0.70912,  0.20409,  0.59842,  0.10021, -0.50464, -0.50126,  0.19531,  0.29624,  0.09606,  0.39679,  0.69318,  0.19678,  0.59666,  0.09949, -0.49788], loss: 1.495e-03\n","iter 62: y_pred = [-0.49558,  0.20378,  0.30697,  0.09972,  0.40553,  0.70943,  0.20422,  0.59891,  0.10046, -0.50411, -0.50096,  0.19541,  0.29618,  0.09607,  0.39697,  0.69321,  0.19675,  0.59633,  0.09922, -0.49847], loss: 1.449e-03\n","iter 63: y_pred = [-0.49571,  0.20347,  0.30674,  0.09952,  0.40556,  0.70967,  0.20432,  0.59937,  0.10069, -0.50357, -0.50067,  0.19556,  0.29616,  0.09612,  0.39714,  0.69325,  0.19674,  0.59605,  0.09897, -0.49903], loss: 1.406e-03\n","iter 64: y_pred = [-0.49588,  0.20314,  0.30649,  0.09934,  0.40556,  0.70984,  0.20438,  0.59979,  0.10092, -0.50303, -0.50039,  0.19575,  0.29618,  0.09619,  0.39732,  0.69332,  0.19674,  0.59581,  0.09874, -0.49957], loss: 1.366e-03\n","iter 65: y_pred = [-0.49607,  0.20282,  0.30622,  0.09918,  0.40551,  0.70994,  0.20441,  0.60017,  0.10112, -0.50250, -0.50013,  0.19596,  0.29622,  0.09630,  0.39750,  0.69340,  0.19675,  0.59561,  0.09852, -0.50007], loss: 1.327e-03\n","iter 66: y_pred = [-0.49630,  0.20249,  0.30593,  0.09904,  0.40543,  0.70999,  0.20441,  0.60051,  0.10131, -0.50199, -0.49988,  0.19620,  0.29631,  0.09644,  0.39769,  0.69350,  0.19678,  0.59545,  0.09832, -0.50055], loss: 1.291e-03\n","iter 67: y_pred = [-0.49655,  0.20216,  0.30562,  0.09891,  0.40532,  0.70998,  0.20440,  0.60082,  0.10147, -0.50149, -0.49965,  0.19646,  0.29642,  0.09660,  0.39789,  0.69362,  0.19683,  0.59533,  0.09814, -0.50100], loss: 1.257e-03\n","iter 68: y_pred = [-0.49682,  0.20184,  0.30529,  0.09880,  0.40518,  0.70992,  0.20437,  0.60109,  0.10161, -0.50100, -0.49945,  0.19674,  0.29655,  0.09678,  0.39810,  0.69376,  0.19690,  0.59523,  0.09797, -0.50141], loss: 1.224e-03\n","iter 69: y_pred = [-0.49710,  0.20151,  0.30494,  0.09869,  0.40502,  0.70982,  0.20432,  0.60132,  0.10174, -0.50054, -0.49926,  0.19702,  0.29671,  0.09698,  0.39832,  0.69392,  0.19698,  0.59517,  0.09781, -0.50179], loss: 1.193e-03\n","iter 70: y_pred = [-0.49740,  0.20119,  0.30458,  0.09860,  0.40482,  0.70966,  0.20426,  0.60153,  0.10185, -0.50010, -0.49910,  0.19730,  0.29689,  0.09719,  0.39855,  0.69409,  0.19708,  0.59513,  0.09767, -0.50214], loss: 1.163e-03\n","iter 71: y_pred = [-0.49771,  0.20088,  0.30421,  0.09851,  0.40461,  0.70946,  0.20419,  0.60172,  0.10194, -0.49967, -0.49895,  0.19759,  0.29708,  0.09742,  0.39878,  0.69429,  0.19720,  0.59513,  0.09754, -0.50245], loss: 1.135e-03\n","iter 72: y_pred = [-0.49802,  0.20058,  0.30384,  0.09843,  0.40437,  0.70922,  0.20410,  0.60187,  0.10202, -0.49928, -0.49883,  0.19788,  0.29728,  0.09766,  0.39903,  0.69450,  0.19733,  0.59516,  0.09743, -0.50273], loss: 1.108e-03\n","iter 73: y_pred = [-0.49833,  0.20028,  0.30346,  0.09836,  0.40412,  0.70893,  0.20400,  0.60201,  0.10208, -0.49890, -0.49872,  0.19817,  0.29748,  0.09790,  0.39927,  0.69472,  0.19748,  0.59521,  0.09733, -0.50297], loss: 1.081e-03\n","iter 74: y_pred = [-0.49864,  0.20000,  0.30308,  0.09830,  0.40385,  0.70861,  0.20389,  0.60213,  0.10213, -0.49856, -0.49863,  0.19845,  0.29769,  0.09814,  0.39951,  0.69496,  0.19764,  0.59530,  0.09725, -0.50318], loss: 1.056e-03\n","iter 75: y_pred = [-0.49895,  0.19973,  0.30270,  0.09824,  0.40356,  0.70824,  0.20376,  0.60223,  0.10217, -0.49823, -0.49855,  0.19874,  0.29790,  0.09838,  0.39975,  0.69521,  0.19781,  0.59541,  0.09719, -0.50335], loss: 1.031e-03\n","iter 76: y_pred = [-0.49925,  0.19947,  0.30233,  0.09819,  0.40326,  0.70784,  0.20362,  0.60231,  0.10220, -0.49794, -0.49848,  0.19901,  0.29811,  0.09862,  0.39998,  0.69547,  0.19799,  0.59555,  0.09714, -0.50349], loss: 1.008e-03\n","iter 77: y_pred = [-0.49955,  0.19923,  0.30196,  0.09816,  0.40294,  0.70741,  0.20347,  0.60237,  0.10222, -0.49767, -0.49843,  0.19928,  0.29833,  0.09886,  0.40021,  0.69573,  0.19818,  0.59571,  0.09711, -0.50360], loss: 9.846e-04\n","iter 78: y_pred = [-0.49984,  0.19900,  0.30160,  0.09813,  0.40262,  0.70695,  0.20330,  0.60242,  0.10223, -0.49742, -0.49840,  0.19955,  0.29854,  0.09909,  0.40043,  0.69600,  0.19837,  0.59589,  0.09709, -0.50368], loss: 9.620e-04\n","iter 79: y_pred = [-0.50012,  0.19879,  0.30125,  0.09811,  0.40229,  0.70646,  0.20313,  0.60245,  0.10223, -0.49720, -0.49837,  0.19980,  0.29874,  0.09932,  0.40063,  0.69628,  0.19857,  0.59610,  0.09710, -0.50373], loss: 9.401e-04\n","iter 80: y_pred = [-0.50038,  0.19859,  0.30092,  0.09810,  0.40196,  0.70596,  0.20294,  0.60246,  0.10222, -0.49701, -0.49836,  0.20005,  0.29895,  0.09955,  0.40082,  0.69656,  0.19877,  0.59632,  0.09712, -0.50375], loss: 9.187e-04\n","iter 81: y_pred = [-0.50064,  0.19841,  0.30059,  0.09810,  0.40163,  0.70543,  0.20275,  0.60246,  0.10220, -0.49685, -0.49836,  0.20029,  0.29915,  0.09976,  0.40100,  0.69685,  0.19897,  0.59656,  0.09715, -0.50374], loss: 8.978e-04\n","iter 82: y_pred = [-0.50088,  0.19826,  0.30028,  0.09812,  0.40130,  0.70490,  0.20255,  0.60244,  0.10216, -0.49672, -0.49837,  0.20052,  0.29935,  0.09997,  0.40117,  0.69713,  0.19916,  0.59681,  0.09720, -0.50370], loss: 8.774e-04\n","iter 83: y_pred = [-0.50111,  0.19812,  0.29998,  0.09814,  0.40098,  0.70436,  0.20234,  0.60241,  0.10212, -0.49661, -0.49839,  0.20074,  0.29955,  0.10018,  0.40132,  0.69741,  0.19936,  0.59707,  0.09726, -0.50364], loss: 8.574e-04\n","iter 84: y_pred = [-0.50133,  0.19799,  0.29970,  0.09817,  0.40066,  0.70381,  0.20213,  0.60236,  0.10207, -0.49652, -0.49841,  0.20095,  0.29974,  0.10037,  0.40146,  0.69769,  0.19955,  0.59734,  0.09733, -0.50356], loss: 8.380e-04\n","iter 85: y_pred = [-0.50153,  0.19789,  0.29943,  0.09821,  0.40034,  0.70326,  0.20192,  0.60230,  0.10201, -0.49646, -0.49845,  0.20115,  0.29992,  0.10056,  0.40159,  0.69797,  0.19973,  0.59762,  0.09742, -0.50346], loss: 8.190e-04\n","iter 86: y_pred = [-0.50171,  0.19780,  0.29918,  0.09826,  0.40004,  0.70271,  0.20170,  0.60223,  0.10194, -0.49643, -0.49850,  0.20133,  0.30010,  0.10073,  0.40170,  0.69824,  0.19991,  0.59790,  0.09752, -0.50334], loss: 8.004e-04\n","iter 87: y_pred = [-0.50188,  0.19773,  0.29895,  0.09832,  0.39975,  0.70217,  0.20149,  0.60214,  0.10187, -0.49642, -0.49855,  0.20150,  0.30027,  0.10090,  0.40180,  0.69851,  0.20008,  0.59818,  0.09762, -0.50320], loss: 7.823e-04\n","iter 88: y_pred = [-0.50203,  0.19768,  0.29874,  0.09838,  0.39947,  0.70164,  0.20128,  0.60204,  0.10178, -0.49643, -0.49862,  0.20165,  0.30043,  0.10105,  0.40188,  0.69877,  0.20025,  0.59847,  0.09774, -0.50305], loss: 7.647e-04\n","iter 89: y_pred = [-0.50217,  0.19764,  0.29854,  0.09845,  0.39920,  0.70112,  0.20107,  0.60194,  0.10170, -0.49646, -0.49869,  0.20178,  0.30058,  0.10119,  0.40195,  0.69902,  0.20041,  0.59875,  0.09786, -0.50288], loss: 7.475e-04\n","iter 90: y_pred = [-0.50228,  0.19762,  0.29836,  0.09853,  0.39895,  0.70062,  0.20087,  0.60182,  0.10160, -0.49652, -0.49876,  0.20191,  0.30073,  0.10133,  0.40201,  0.69927,  0.20055,  0.59902,  0.09799, -0.50270], loss: 7.308e-04\n","iter 91: y_pred = [-0.50238,  0.19762,  0.29820,  0.09860,  0.39872,  0.70014,  0.20067,  0.60170,  0.10150, -0.49659, -0.49884,  0.20201,  0.30086,  0.10144,  0.40205,  0.69951,  0.20069,  0.59929,  0.09812, -0.50251], loss: 7.146e-04\n","iter 92: y_pred = [-0.50247,  0.19763,  0.29806,  0.09869,  0.39850,  0.69967,  0.20047,  0.60157,  0.10140, -0.49668, -0.49892,  0.20210,  0.30099,  0.10155,  0.40209,  0.69973,  0.20082,  0.59956,  0.09826, -0.50231], loss: 6.989e-04\n","iter 93: y_pred = [-0.50253,  0.19765,  0.29794,  0.09877,  0.39830,  0.69923,  0.20029,  0.60144,  0.10130, -0.49678, -0.49901,  0.20218,  0.30110,  0.10164,  0.40211,  0.69995,  0.20094,  0.59982,  0.09840, -0.50210], loss: 6.836e-04\n","iter 94: y_pred = [-0.50258,  0.19769,  0.29784,  0.09886,  0.39811,  0.69881,  0.20011,  0.60130,  0.10119, -0.49690, -0.49910,  0.20224,  0.30120,  0.10172,  0.40211,  0.70015,  0.20105,  0.60007,  0.09854, -0.50189], loss: 6.688e-04\n","iter 95: y_pred = [-0.50262,  0.19773,  0.29775,  0.09895,  0.39795,  0.69841,  0.19994,  0.60117,  0.10108, -0.49703, -0.49919,  0.20228,  0.30129,  0.10179,  0.40211,  0.70035,  0.20115,  0.60031,  0.09869, -0.50167], loss: 6.544e-04\n","iter 96: y_pred = [-0.50264,  0.19779,  0.29768,  0.09905,  0.39780,  0.69804,  0.19977,  0.60102,  0.10098, -0.49718, -0.49928,  0.20231,  0.30137,  0.10185,  0.40210,  0.70053,  0.20124,  0.60053,  0.09883, -0.50145], loss: 6.406e-04\n","iter 97: y_pred = [-0.50264,  0.19786,  0.29763,  0.09914,  0.39767,  0.69770,  0.19962,  0.60088,  0.10087, -0.49733, -0.49938,  0.20233,  0.30144,  0.10189,  0.40207,  0.70069,  0.20132,  0.60075,  0.09898, -0.50123], loss: 6.271e-04\n","iter 98: y_pred = [-0.50263,  0.19794,  0.29760,  0.09923,  0.39755,  0.69738,  0.19948,  0.60074,  0.10076, -0.49749, -0.49947,  0.20233,  0.30150,  0.10192,  0.40204,  0.70085,  0.20138,  0.60096,  0.09912, -0.50100], loss: 6.142e-04\n","iter 99: y_pred = [-0.50260,  0.19803,  0.29758,  0.09932,  0.39746,  0.69709,  0.19934,  0.60060,  0.10065, -0.49767, -0.49956,  0.20232,  0.30154,  0.10194,  0.40199,  0.70099,  0.20144,  0.60115,  0.09926, -0.50079], loss: 6.016e-04\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(llst,  label='BPTT - full')\n","plt.plot(llst1,  label='BPTT - 0')\n","plt.plot(llst2,  label='BPTT - 0 - online')\n","plt.plot(llst3,  label='FPTT')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"loss\")\n","plt.legend(loc='upper right')\n","plt.title(\"Convergence Speed of training algorithms on LSTM (the number of epoch needed)\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"ok","timestamp":1684711836911,"user_tz":-120,"elapsed":494,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}},"outputId":"68478bed-f841-4e60-8cc6-80d55e30afcb","id":"NhLa2RZiGz0w"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"gNILuWS5IUi0","executionInfo":{"status":"ok","timestamp":1684711836912,"user_tz":-120,"elapsed":10,"user":{"displayName":"Yicheng Zhang","userId":"07157030176331289981"}}},"execution_count":56,"outputs":[]}]}